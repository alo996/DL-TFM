{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df3eb3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preprocessing and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f7f65",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "presidential-prophet",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tracNet import TracNet\n",
    "from data_preparation import matFiles_to_npArray, extract_fields, reshape\n",
    "from training_and_evaluation import initialize_weights, fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-while",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composite-undergraduate",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-tackle",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immune-bosnia",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-optics",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-suffering",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set paths to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metric-packet",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Martinsried\n",
    "dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/dspl'\n",
    "dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/dsplRadial'\n",
    "trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/trac'\n",
    "tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/tracRadial'\n",
    "\n",
    "# Macbook\n",
    "# dspl_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_dspl'\n",
    "# dsplRadial_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_dsplRadial'\n",
    "# trac_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_trac'\n",
    "# tracRadial_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-piano",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create `ndarrays` of `dicts` containing either the inputs or targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "departmental-eagle",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples = matFiles_to_npArray(dspl_path) # each dict has keys ['brdx', 'brdy', 'dspl', 'name']\n",
    "dspl_radials = matFiles_to_npArray(dsplRadial_path) # each dict has keys ['dspl', 'name']\n",
    "targets = matFiles_to_npArray(trac_path) # each dict has keys ['brdx', 'brdy', 'trac', 'name']\n",
    "trac_radials = matFiles_to_npArray(tracRadial_path) # each dict has keys ['trac', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-sleep",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split training data into train and validation set using stratified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "standard-research",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "radial_X_train, radial_X_val, radial_y_train, radial_y_val = train_test_split(dspl_radials, trac_radials, test_size=0.05)\n",
    "X_train, X_val, y_train, y_val = train_test_split(samples, targets, test_size=0.05)\n",
    "X_train, X_val, y_train, y_val = np.append(radial_X_train, X_train), np.append(radial_X_val, X_val), np.append(radial_y_train, y_train), np.append(radial_y_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-hunger",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Extract displacement and traction fields from the data and drop (meta-) data which is not needed for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adjacent-france",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = extract_fields(X_train)\n",
    "X_val = extract_fields(X_val)\n",
    "y_train = extract_fields(y_train)\n",
    "y_val = extract_fields(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-closer",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Current shape of the datasets is (samples, width, height, depth). \n",
    "Reshape them to (samples, channels, depth, height, width) to allow 3D-Convolutions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "first-relations",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = reshape(X_train)\n",
    "X_val = reshape(X_val)\n",
    "y_train = reshape(y_train)\n",
    "y_val = reshape(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-control",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert datasets to Pytorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "therapeutic-heart",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).double()\n",
    "X_val = torch.from_numpy(X_val).double()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_val = torch.from_numpy(y_val).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-edition",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create Pytorch dataloaders, specify batch sizes and number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interracial-budget",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=12, pin_memory=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=10*batch_size, num_workers=12, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-popularity",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-violation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define custom loss function corresponding to the forward loss function in the Matlab regression layer for image-to-image networks:\n",
    " \n",
    "$${loss} = \\frac{1}{2} \\sum \\limits _{p=1} ^{HWC} (t_{p} - y_{p})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "royal-blast",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Custom_Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_Loss, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss = 0.5 * torch.sum(torch.pow(target - predictions, 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-glance",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Instantiate the model (including logs for evaluation), the optimizer and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-camcorder",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:07:59.084493: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-17 13:07:59.084515: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexrichard/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:587: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.0000e-04.\n",
      "Epoch 1/100, train_loss: 81.345, train_rmse: 12.755, val_loss: 52.286, val_rmse: 10.226\n",
      "best val_rmse: 10.226, epoch: 1, best_epoch: 1, current_patience: 5\n",
      "Adjusting learning rate of group 0 to 6.0000e-04.\n",
      "Epoch 2/100, train_loss: 25.855, train_rmse: 7.191, val_loss: 17.980, val_rmse: 5.997\n",
      "best val_rmse: 5.997, epoch: 2, best_epoch: 2, current_patience: 5\n"
     ]
    }
   ],
   "source": [
    "NAME = \"TracNet104-{:%Y-%b-%d %H:%M:%S}\".format(datetime.now())\n",
    "writer = SummaryWriter(log_dir='logs/{}'.format(NAME))\n",
    "model = TracNet(n_channels=1).double()\n",
    "model.to(device)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# To create a computional graph in Tensorboard, uncomment the following lines.\n",
    "# inputs, targets = next(iter(dataloaders['train']))\n",
    "# inputs = inputs.to(device)\n",
    "# targets = targets.to(device)\n",
    "# writer.add_graph(model, inputs)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0006, weight_decay=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.7943, verbose=True)\n",
    "loss_fn = Custom_Loss()\n",
    "\n",
    "fit(model, loss_fn, scheduler, dataloaders, optimizer, device, writer, NAME, max_epochs=100, patience=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}