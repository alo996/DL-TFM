{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "growing-maldives",
   "metadata": {},
   "source": [
    "This notebook can be used to train a new CNN from scratch to predict cellular forces from given displacement fields. As of now we only support input shapes of 104 x 104 x 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-williams",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "presidential-prophet",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.tracNet import TracNet\n",
    "from scripts.data_preparation import matFiles_to_npArray, extract_fields, reshape\n",
    "from scripts.training_and_evaluation import initialize_weights, fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from os import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-while",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composite-undergraduate",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-tackle",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immune-bosnia",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-optics",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-suffering",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Download data from https://cmu.app.box.com/s/n34hbfopwa3r6rftvtfn4ckc403hk43d and place it in a .data/ folder in your directory. We store the inputs and targets of resolution 104 x 104 in ndarrays of dicts with the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "departmental-eagle",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples = matFiles_to_npArray('data/train/trainData104/foo_dspl') # each dict has keys ['brdx', 'brdy', 'dspl', 'name']\n",
    "dspl_radials = matFiles_to_npArray('data/train/trainData104/foo_dsplRadial') # each dict has keys ['dspl', 'name']\n",
    "targets = matFiles_to_npArray('data/train/trainData104/foo_trac') # each dict has keys ['brdx', 'brdy', 'trac', 'name']\n",
    "trac_radials = matFiles_to_npArray('data/train/trainData104/foo_tracRadial') # each dict has keys ['trac', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-sleep",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split training data into train and validation set using stratified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "standard-research",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "radial_X_train, radial_X_val, radial_y_train, radial_y_val = train_test_split(dspl_radials, trac_radials, test_size=0.05)\n",
    "X_train, X_val, y_train, y_val = train_test_split(samples, targets, test_size=0.05)\n",
    "X_train, X_val, y_train, y_val = np.append(radial_X_train, X_train), np.append(radial_X_val, X_val), np.append(radial_y_train, y_train), np.append(radial_y_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-hunger",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Extract displacement and traction fields from the data and drop (meta-) data which is not needed for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjacent-france",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = extract_fields(X_train)\n",
    "X_val = extract_fields(X_val)\n",
    "y_train = extract_fields(y_train)\n",
    "y_val = extract_fields(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-closer",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Current shape of the datasets is (samples, width, height, depth). \n",
    "Reshape them to (samples, channels, depth, height, width) to allow 3D-Convolutions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "first-relations",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = reshape(X_train)\n",
    "X_val = reshape(X_val)\n",
    "y_train = reshape(y_train)\n",
    "y_val = reshape(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-control",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert datasets to Pytorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "therapeutic-heart",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).double()\n",
    "X_val = torch.from_numpy(X_val).double()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_val = torch.from_numpy(y_val).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-edition",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Specify batch sizes and number of workers (the proposed choice is based on my experience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interracial-budget",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "if device == 'cpu':\n",
    "    num_workers = os.cpu_count()\n",
    "else:\n",
    "    num_workers = 4 * torch.cuda.device_count()\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=10*batch_size, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-popularity",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-violation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define custom loss function corresponding to the forward loss function in the MATLAB regression layer for image-to-image networks (HWC: height * width * channels of inputs):\n",
    " \n",
    "$${loss} = \\frac{1}{2} \\sum \\limits _{p=1} ^{HWC} (t_{p} - y_{p})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "royal-blast",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Custom_Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_Loss, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss = 0.5 * torch.sum(torch.pow(target - predictions, 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-glance",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Instantiate the model (including logs for evaluation), the optimizer and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "strategic-camcorder",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/2 [00:00<?, ?batch/s]/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py:585: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n",
      "  return F.conv3d(\n",
      "Epoch 1: 100%|██████████| 2/2 [02:02<00:00, 61.12s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:01<00:00,  1.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train_loss: 239.031, train_rmse: 21.865, val_loss: 334.076, val_rmse: 25.849\n",
      "best val_rmse: 25.849, epoch: 1, best_epoch: 1, current_patience: 5\n"
     ]
    }
   ],
   "source": [
    "NAME = \"TracNet104-{:%Y-%b-%d %H:%M:%S}\".format(datetime.now())\n",
    "writer = SummaryWriter(log_dir='{}'.format(NAME))\n",
    "model = TracNet(n_channels=1).double()\n",
    "model.to(device)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0006, weight_decay=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.7943, verbose=True)\n",
    "loss_fn = Custom_Loss()\n",
    "\n",
    "fit(model, loss_fn, scheduler, dataloaders, optimizer, device, writer, NAME, max_epochs=1, patience=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
