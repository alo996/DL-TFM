{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df3eb3e",
   "metadata": {},
   "source": [
    "# Data preprocessing and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f7f65",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "presidential-prophet",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tracNet import TracNet\n",
    "from data_preparation import matFiles_to_npArray, extract_fields, reshape\n",
    "from training_and_evaluation import initialize_weights, fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-while",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "composite-undergraduate",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-tackle",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immune-bosnia",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-optics",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-suffering",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set paths to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "metric-packet",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Martinsried\n",
    "# dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/dspl'\n",
    "# dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/dsplRadial'\n",
    "# trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/trac'\n",
    "# tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/tracRadial'\n",
    "\n",
    "# Macbook\n",
    "dspl_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_dspl'\n",
    "dsplRadial_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_dsplRadial'\n",
    "trac_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_trac'\n",
    "tracRadial_path = '/Users/alex/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-piano",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create `ndarrays` of `dicts` containing either the inputs or targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "departmental-eagle",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples = matFiles_to_npArray(dspl_path) # each dict has keys ['brdx', 'brdy', 'dspl', 'name']\n",
    "dspl_radials = matFiles_to_npArray(dsplRadial_path) # each dict has keys ['dspl', 'name']\n",
    "targets = matFiles_to_npArray(trac_path) # each dict has keys ['brdx', 'brdy', 'trac', 'name']\n",
    "trac_radials = matFiles_to_npArray(tracRadial_path) # each dict has keys ['trac', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-sleep",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split training data into train and validation set using stratified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "standard-research",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "radial_X_train, radial_X_val, radial_y_train, radial_y_val = train_test_split(dspl_radials, trac_radials, test_size=0.05)\n",
    "X_train, X_val, y_train, y_val = train_test_split(samples, targets, test_size=0.05)\n",
    "X_train, X_val, y_train, y_val = np.append(radial_X_train, X_train), np.append(radial_X_val, X_val), np.append(radial_y_train, y_train), np.append(radial_y_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-hunger",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Extract displacement and traction fields from the data and drop (meta-) data which is not needed for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adjacent-france",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = extract_fields(X_train)\n",
    "X_val = extract_fields(X_val)\n",
    "y_train = extract_fields(y_train)\n",
    "y_val = extract_fields(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-closer",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Current shape of the datasets is (samples, width, height, depth). \n",
    "Reshape them to (samples, channels, depth, height, width) to allow 3D-Convolutions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "first-relations",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = reshape(X_train)\n",
    "X_val = reshape(X_val)\n",
    "y_train = reshape(y_train)\n",
    "y_val = reshape(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-control",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert datasets to Pytorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "therapeutic-heart",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).double()\n",
    "X_val = torch.from_numpy(X_val).double()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_val = torch.from_numpy(y_val).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-edition",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create Pytorch dataloaders, specify batch sizes and number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interracial-budget",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=2*batch_size, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-popularity",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-violation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define custom loss function corresponding to the forward loss function in the Matlab regression layer for image-to-image networks:\n",
    " \n",
    "$${loss} = \\frac{1}{2} \\sum \\limits _{p=1} ^{HWC} (t_{p} - y_{p})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "royal-blast",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Custom_Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_Loss, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss = 0.5 * torch.sum(torch.pow(target - predictions, 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-glance",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Instantiate the model (including logs for evaluation), the optimizer and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "strategic-camcorder",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "NAME = \"TracNet104-{:%Y-%b-%d %H:%M:%S}\".format(datetime.now())\n",
    "writer = SummaryWriter(log_dir='logs/{}'.format(NAME))\n",
    "model = TracNet(n_channels=1).double()\n",
    "model.to(device)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# To create a computional graph in Tensorboard, uncomment the following lines.\n",
    "# inputs, targets = next(iter(dataloaders['train']))\n",
    "# inputs = inputs.to(device)\n",
    "# targets = targets.to(device)\n",
    "# writer.add_graph(model, inputs)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0006, weight_decay=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.7943, verbose=True)\n",
    "loss_fn = Custom_Loss()\n",
    "\n",
    "# fit(model, loss_fn, scheduler, dataloaders, optimizer, device, max_epochs=100, patience=5, writer, NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
