{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2774dc7e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7b354df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import shapely as sh\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Accuracy, RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, Activation, \\\n",
    "    Concatenate\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764f8b7",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "01828116",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/dspl'\n",
    "dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/dsplRadial'\n",
    "trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/trac'\n",
    "tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f86cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af2cb1",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad1b179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters, snd_batch_normalization=True):\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    x = Conv2D(filters=num_filters, kernel_size=(3, 3), padding='same', kernel_initializer=initializer,\n",
    "               bias_initializer='zeros')(input)\n",
    "    print(x.shape)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(filters=num_filters, kernel_size=(3, 3), padding='same', kernel_initializer=initializer,\n",
    "               bias_initializer='zeros')(x)\n",
    "    print(x.shape)\n",
    "    if snd_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "70b56733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters, snd_batch_normalization=False)\n",
    "    print(x.shape)\n",
    "    p = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    print(p.shape)\n",
    "\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(input, skip_features, num_filters):\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    x = Conv2DTranspose(filters=num_filters, kernel_size=(3, 3), strides=(2, 2),\n",
    "                        kernel_initializer=initializer, bias_initializer='zeros', padding='same')(input)\n",
    "    print(x.shape)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters, snd_batch_normalization=True)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1b59a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tracnet(input_shape, batch_size):\n",
    "    # entry point into graph of layers\n",
    "    inputs = Input(shape=input_shape, batch_size=batch_size)\n",
    "    print(inputs.shape)\n",
    "\n",
    "    # convolution and max-pooling operations with specified numbers of filters\n",
    "    s1, p1 = encoder_block(inputs, 32)\n",
    "    s2, p2 = encoder_block(p1, 64)\n",
    "    s3, p3 = encoder_block(p2, 128)\n",
    "\n",
    "    # base\n",
    "    b1 = conv_block(p3, 256)\n",
    "\n",
    "    # convolution and upsampling operations with specified numbers of filters\n",
    "    d1 = decoder_block(b1, s3, 128)\n",
    "    d2 = decoder_block(d1, s2, 64)\n",
    "    d3 = decoder_block(d2, s1, 32)\n",
    "\n",
    "    # output\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    outputs = Conv2D(filters=2, kernel_size=(3, 3), padding='same', kernel_initializer=initializer,\n",
    "                     bias_initializer='zeros')(d3)\n",
    "\n",
    "    # build model\n",
    "    model = Model(inputs, outputs, name='Tracnet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658c6b3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8856e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tracnet(dspl_train, trc_train, dspl_test, trc_test, input_shape=(104, 104, 2), epochs=100):\n",
    "    batch_size = 32\n",
    "    model = build_tracnet(input_shape, batch_size)\n",
    "    model.compile(\n",
    "        optimizer=SGD(momentum=0.9),\n",
    "        loss=MeanSquaredError(),\n",
    "        metrics=[Accuracy(), RootMeanSquaredError(), MeanAbsoluteError()]\n",
    "    )\n",
    "    model.summary()\n",
    "    history = model.fit(\n",
    "        dspl_train,\n",
    "        trc_train,\n",
    "        validation_data=(dspl_test, trc_test),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[LearningRateScheduler(lr_step_decay, verbose=2)],\n",
    "        verbose=2\n",
    "    )\n",
    "    # plot accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig('accuracy_1.png')\n",
    "    plt.close()\n",
    "\n",
    "    # plot loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig('loss_1.png')\n",
    "    plt.close()\n",
    "\n",
    "    # plot rmse\n",
    "    plt.plot(history.history['root_mean_squared_error'])\n",
    "    plt.plot(history.history['val_root_mean_squared_error'])\n",
    "    plt.title('model rmse')\n",
    "    plt.ylabel('rmse')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig('rmse_1.png')\n",
    "    plt.close()\n",
    "\n",
    "    # save model\n",
    "    model.save(\"'model_1.tf'\",save_format='tf',include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_step_decay(epoch):\n",
    "    initial_lr = 6e-4\n",
    "    drop_rate = 0.7943\n",
    "    epochs_drop = 10.0\n",
    "    \n",
    "    return initial_lr * np.power(drop_rate, np.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475f337",
   "metadata": {},
   "source": [
    "## Error calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a197c33",
   "metadata": {},
   "source": [
    "For a given displacement field, calculate the predicted stress field and the normalized rmse relative to its ground truth for different Young's moduli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fadc0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(path):\n",
    "    errors = []\n",
    "    S = 160\n",
    "    y_moduli = [2500, 5000, 10000, 20000, 400000]\n",
    "    noise = 0.00765\n",
    "    for nr in range(18, 56):\n",
    "        name = f'MLData00{nr}.mat'.format\n",
    "        path = os.path.join(path, name)\n",
    "        if os.path.isfile(path):\n",
    "            cell = [nr]\n",
    "            trac_file = loadmat(path)\n",
    "            brdx = trac_file['brdx']\n",
    "            brdy = trac_file['brdy']\n",
    "            tracGT = trac_file['tracGT']\n",
    "            for i in y_moduli:\n",
    "                name = f'MLData00{nr}-{i}.mat'.format(nr=nr, i=i)\n",
    "                path = os.path.join(path, name)\n",
    "                if os.path.isfile(path):\n",
    "                    dspl_file = loadmat(path)\n",
    "                    dspl = dspl_file['dspl']\n",
    "                    trac = predictTrac(dspl, i)\n",
    "                    err = errorTrac(trac, tracGT, brdx, brdy)\n",
    "                    cell.append(err)\n",
    "\n",
    "                    dspl = addNoise(dspl, noise)\n",
    "                    trac = predictTrac(dspl, i)\n",
    "                    err = errorTrac(trac, tracGT, brdx, brdy)\n",
    "                    cell.append(err)\n",
    "                else:\n",
    "                    continue\n",
    "            errors.append(cell)\n",
    "        else:\n",
    "            continue\n",
    "    df = pd.DataFrame(errors, index=['first', 'second'],\n",
    "                      columns=['File ID', '2,500Pa', '2,500Pa N', '5,000Pa', '5,000Pa N', '10,000Pa', '10,000Pa N',\n",
    "                               '20,000Pa', '20,000Pa N', '40,000Pa', '40,000Pa N'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119573f7",
   "metadata": {},
   "source": [
    "`errorTrac` is called by `calcError` to actually perform the error calculation given a predicted stress field and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f93cdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorTrac(filepath, filepath_GT, plot=False):\n",
    "    file = loadmat(filepath)  # load prediction\n",
    "    file_GT = loadmat(filepath_GT) # load ground truth\n",
    "    brdx = file['brdx']  # x-values of predicted cell border\n",
    "    brdy = file['brdy']  # y-values of predicted cell border\n",
    "    trac = file['trac']\n",
    "    tracGT = file_GT['trac']\n",
    "    zipped = np.array(list(zip(brdx[0], brdy[0])))  # array with (x,y) pairs of cell border coordinates\n",
    "    polygon = sh.geometry.Polygon(zipped)  # create polygon\n",
    "\n",
    "    interior = np.zeros((file['dspl'].shape[0], file['dspl'].shape[1]), dtype=int)  # create all zero matrix\n",
    "    for i in range(len(interior)):  # set all elements in interior matrix to 1 that actually lie within the cell\n",
    "        for j in range(len(interior[i])):\n",
    "            point = Point(i, j)\n",
    "            if polygon.contains(point):\n",
    "                interior[i][j] = 1\n",
    "\n",
    "    # plot polygons using geopandas\n",
    "    if plot:\n",
    "        p = gpd.GeoSeries(polygon)\n",
    "        p.plot()\n",
    "        plt.show()\n",
    "\n",
    "    # update prediction and ground truth by discarding areas outside of cell borders\n",
    "    trac[:, :, 1] = trac[:, :, 1] * interior\n",
    "    trac[:, :, 2] = trac[:, :, 2] * interior\n",
    "    tracGT[:, :, 1] = tracGT[:, :, 1] * interior\n",
    "    tracGT[:, :, 2] = tracGT[:, :, 2] * interior\n",
    "\n",
    "    # compute rmse\n",
    "    mse = np.sum(np.pow((trac[:, :, 1] - tracGT[:, :, 1], 2)), np.pow((trac[:, :, 2] - tracGT[:, :, 2], 2)))\n",
    "    rmse = np.sqrt(mse)\n",
    "    msm = np.sum(np.pow(tracGT[:, :, 1], 2) + np.pow(tracGT[:, :, 2], 2))\n",
    "    rmsm = np.sqrt(msm)\n",
    "    error = rmse / rmsm\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789be81",
   "metadata": {},
   "source": [
    "`add_noise` applies Gaussian noise to a displacement field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c394fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(dspl, N):\n",
    "    dsplN = np.zeros(shape=dspl.shape)\n",
    "    S = dspl.shape[0]\n",
    "    stdev = N / np.sqrt(2)\n",
    "    noise = np.random.normal(loc=0, scale=stdev, size=(S, S))\n",
    "    dsplN[:, :, 1] = dspl[:, :, 1] + noise\n",
    "    noise = np.random.normal(loc=0, scale=stdev, size=(S, S))\n",
    "    dsplN[:, :, 2] = dspl[:, :, 2] + noise\n",
    "    \n",
    "    return dsplN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e35c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}