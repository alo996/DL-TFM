{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd3f144",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e78ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import shapely as sh\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as math\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Accuracy, RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Conv3DTranspose, BatchNormalization, Activation, \\\n",
    "    Concatenate\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec28190",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702a3dd",
   "metadata": {},
   "source": [
    "Specify paths to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ff49bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For working remotely on CIP machines\n",
    "# dspl_path = '/home/r/richard/Downloads/train/trainData104/dspl'\n",
    "# dsplRadial_path = '/home/r/richard/Downloads/train/trainData104/dsplRadial'\n",
    "# trac_path = '/home/r/richard/Downloads/train/trainData104/trac'\n",
    "# tracRadial_path = '/home/r/richard/Downloads/train/trainData104/tracRadial'\n",
    "\n",
    "# Paths to small subsets of original data for bug fixing\n",
    "# foo_dspl_path = '/home/r/richard/Downloads/train/trainData104/foo_dspl'\n",
    "# foo_dsplRadial_path = '/home/r/richard/Downloads/train/trainData104/foo_dsplRadial'\n",
    "# foo_trac_path = '/home/r/richard/Downloads/train/trainData104/foo_trac'\n",
    "# foo_tracRadial_path = '/home/r/richard/Downloads/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4c6febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For working on Martinsried machine\n",
    "dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/dspl'\n",
    "dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/dsplRadial'\n",
    "trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/trac'\n",
    "tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/tracRadial'\n",
    "\n",
    "# Paths to small subsets of original data for bug fixing\n",
    "#foo_dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_dspl'\n",
    "#foo_dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_dsplRadial'\n",
    "#foo_trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_trac'\n",
    "#foo_tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a86c4",
   "metadata": {},
   "source": [
    "`datasets` saves the training and test data in arrays of dictionaries of the form {'brdx': array, 'brdy': array, 'dspl' or 'trac' = array, 'name': String}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f8ec6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b5d3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4551822",
   "metadata": {},
   "source": [
    "Set seed for reproducability and generate the training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6f99d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "samples, dspl_radials, targets, trac_radials = datasets(dspl_path, dsplRadial_path, trac_path, tracRadial_path)\n",
    "samples, targets = np.append(samples, dspl_radials), np.append(targets, trac_radials)\n",
    "\n",
    "X, y = np.array([sample['dspl'] for sample in samples]), np.array([target['trac'] for target in targets])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = X_train.reshape(((len(X_train), 104, 104, 2, 1))), X_val.reshape(((len(X_val), 104, 104, 2, 1))), y_train.reshape(((len(y_train), 104, 104, 2, 1))), y_val.reshape(((len(y_val), 104, 104, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b829b73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'axis' must be None, an integer, or a tuple of 2 unique integers, got (1, 2, 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [164]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m y_val \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(y_val)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Normalize\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m X_train \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/linalg_ops.py:720\u001B[0m, in \u001B[0;36mnorm\u001B[0;34m(tensor, ord, axis, keepdims, name, keep_dims)\u001B[0m\n\u001B[1;32m    718\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    719\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(axis, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 720\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    721\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maxis\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be None, an integer, or a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    722\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtuple of 2 unique integers, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    724\u001B[0m   supported_vector_norms \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meuclidean\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, np\u001B[38;5;241m.\u001B[39minf]\n\u001B[1;32m    725\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misreal(\u001B[38;5;28mord\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mord\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mord\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m supported_vector_norms:\n",
      "\u001B[0;31mValueError\u001B[0m: 'axis' must be None, an integer, or a tuple of 2 unique integers, got (1, 2, 3)"
     ]
    }
   ],
   "source": [
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "# Normalize\n",
    "X_train = tf.linalg.normalize(X_train, axis=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073614e0",
   "metadata": {},
   "source": [
    "Create tf.Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "69bf558b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TensorSliceDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [145]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices((X_val, y_val))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Normalize\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnormalize(\u001B[43mtrain_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m, axis\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m      7\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m train_dataset\u001B[38;5;241m.\u001B[39mbatch(batch_size)\n\u001B[1;32m      8\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m val_dataset\u001B[38;5;241m.\u001B[39mbatch(batch_size)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'TensorSliceDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1c31",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e937491",
   "metadata": {},
   "source": [
    "Specify the name and logs of the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dfe98667",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"TracNet104-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5d671f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_1(input, num_filters, trans_conv=False):\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    x = Conv3D(filters=num_filters, kernel_size=(3, 3, 2), padding='same', kernel_initializer=initializer,\n",
    "               bias_initializer='zeros')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    if trans_conv:\n",
    "        x = Conv3DTranspose(filters=num_filters, kernel_size=(3, 3, 1), strides=(2, 2, 1),\n",
    "                        kernel_initializer=initializer, bias_initializer='zeros', padding='same')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6ff34644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_2(input, num_filters):\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    x = Conv3D(filters=num_filters, kernel_size=(3, 3, 2), padding='same', kernel_initializer=initializer,\n",
    "               bias_initializer='zeros')(input)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "43a13ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tracnet(input_shape, batch_size):\n",
    "    # entry point into graph of layers\n",
    "    inputs = Input(shape=input_shape, batch_size=batch_size)\n",
    "    \n",
    "    s1 = conv_block_1(inputs, 32)\n",
    "    \n",
    "    s2 = conv_block_2(s1, 64)\n",
    "    \n",
    "    s3 = MaxPooling3D(pool_size=(2, 2, 1), strides=(2, 2, 1), padding='same')(s2)\n",
    "\n",
    "    s4 = conv_block_1(s3, 64)\n",
    "    \n",
    "    s5 = conv_block_2(s4, 128)\n",
    "    \n",
    "    s6 = MaxPooling3D(pool_size=(2, 2, 1), strides=(2, 2, 1), padding='same')(s5)\n",
    "\n",
    "    s7 = conv_block_1(s6, 128)\n",
    "    \n",
    "    s8 = conv_block_2(s7, 256)\n",
    "    \n",
    "    s9 = MaxPooling3D(pool_size=(2, 2, 1), strides=(2, 2, 1), padding='same')(s8)\n",
    "    \n",
    "    s10 = conv_block_1(s9, 128)\n",
    "    \n",
    "    s11 = conv_block_1(s10, 256, trans_conv=True)\n",
    "    \n",
    "    fusion3 = tf.concat([s8, s11], -1)\n",
    "    \n",
    "    s12 = conv_block_1(fusion3, 64)\n",
    "    \n",
    "    s13 = conv_block_1(s12, 128, trans_conv=True)\n",
    "    \n",
    "    fusion2 = tf.concat([s5, s13], -1)\n",
    "    \n",
    "    s14 = conv_block_1(fusion2, 32)\n",
    "    \n",
    "    s15 = conv_block_1(s14, 64, trans_conv=True)\n",
    "    \n",
    "    fusion1 = tf.concat([s2, s15], -1)\n",
    "    \n",
    "    s16 = conv_block_1(fusion1, 1)\n",
    "    \n",
    "    s17 = conv_block_1(s16, 32)\n",
    "    \n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    outputs = Conv3D(filters=1, kernel_size=(3, 3, 2), padding='same', kernel_initializer=initializer,\n",
    "                     bias_initializer='zeros')(s17)\n",
    "\n",
    "    # build model\n",
    "    model = Model(inputs, outputs, name=NAME)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a76cc6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496fc20",
   "metadata": {},
   "source": [
    "Define loss function as \n",
    "$${loss} = \\frac{1}{2} \\sum \\limits _{p=1} ^{HWC} (t_{p} - y_{p})^{2}$$\n",
    "Idea: compare ground truth and prediction of each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0dfc9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_mse(t, y):\n",
    "    return math.scalar_mul(math.pow((0.5, math.reduce_sum(t - y)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "31ea160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_step_decay(epoch):\n",
    "    initial_lr = 6e-4\n",
    "    drop_rate = 0.7943\n",
    "    epochs_drop = 10.0\n",
    "    \n",
    "    return initial_lr * np.power(drop_rate, np.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3ee7b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class haltCallback(tf.keras.callbacks.Callback):\n",
    "#def on_epoch_end(self, epoch, logs={}):\n",
    "#if(logs.get('half_mse') < 3):\n",
    "#    print(\"\\n\\n\\nLoss value below 3 so cancelling training!\\n\\n\\n\")\n",
    "#    self.model.stop_training = True\n",
    "#\n",
    "#trainingStopCallback = haltCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f9d309d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tracnet(dev_set, val_set, input_shape=(104, 104, 2, 1), epochs=50):\n",
    "    batch_size = 30\n",
    "    # Input layer expects (batch size, length, width, depth, channels\n",
    "    \n",
    "    model = build_tracnet(input_shape, batch_size)\n",
    "    model.compile(\n",
    "        optimizer=SGD(momentum=0.9),\n",
    "        loss = half_mse,\n",
    "        metrics=['accuracy', half_mse],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(\n",
    "        dev_set,\n",
    "        validation_data=val_set,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[LearningRateScheduler(lr_step_decay, verbose=2), tensorboard],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # plot accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # plot loss\n",
    "    plt.plot(history.history['half_mse'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"{}.tf\".format(NAME),save_format='tf',include_optimizer=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3dd3ec82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TracNet104-1648031491\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(30, 104, 104, 2,   0           []                               \n",
      "                                1)]                                                               \n",
      "                                                                                                  \n",
      " conv3d_30 (Conv3D)             (30, 104, 104, 2, 3  608         ['input_3[0][0]']                \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (30, 104, 104, 2, 3  128        ['conv3d_30[0][0]']              \n",
      " ormalization)                  2)                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (30, 104, 104, 2, 3  0           ['batch_normalization_22[0][0]'] \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_31 (Conv3D)             (30, 104, 104, 2, 6  36928       ['activation_28[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (30, 104, 104, 2, 6  0           ['conv3d_31[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " max_pooling3d_6 (MaxPooling3D)  (30, 52, 52, 2, 64)  0          ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_32 (Conv3D)             (30, 52, 52, 2, 64)  73792       ['max_pooling3d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (30, 52, 52, 2, 64)  256        ['conv3d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (30, 52, 52, 2, 64)  0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv3d_33 (Conv3D)             (30, 52, 52, 2, 128  147584      ['activation_30[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (30, 52, 52, 2, 128  0           ['conv3d_33[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_7 (MaxPooling3D)  (30, 26, 26, 2, 128  0          ['activation_31[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_34 (Conv3D)             (30, 26, 26, 2, 128  295040      ['max_pooling3d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (30, 26, 26, 2, 128  512        ['conv3d_34[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (30, 26, 26, 2, 128  0           ['batch_normalization_24[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_35 (Conv3D)             (30, 26, 26, 2, 256  590080      ['activation_32[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (30, 26, 26, 2, 256  0           ['conv3d_35[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_8 (MaxPooling3D)  (30, 13, 13, 2, 256  0          ['activation_33[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_36 (Conv3D)             (30, 13, 13, 2, 128  589952      ['max_pooling3d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (30, 13, 13, 2, 128  512        ['conv3d_36[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (30, 13, 13, 2, 128  0           ['batch_normalization_25[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_37 (Conv3D)             (30, 13, 13, 2, 256  590080      ['activation_34[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (30, 13, 13, 2, 256  1024       ['conv3d_37[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (30, 13, 13, 2, 256  0           ['batch_normalization_26[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_6 (Conv3DTran  (30, 26, 26, 2, 256  590080     ['activation_35[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)       (30, 26, 26, 2, 512  0           ['activation_33[0][0]',          \n",
      "                                )                                 'conv3d_transpose_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_38 (Conv3D)             (30, 26, 26, 2, 64)  589888      ['tf.concat_6[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (30, 26, 26, 2, 64)  256        ['conv3d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (30, 26, 26, 2, 64)  0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv3d_39 (Conv3D)             (30, 26, 26, 2, 128  147584      ['activation_36[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (30, 26, 26, 2, 128  512        ['conv3d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (30, 26, 26, 2, 128  0           ['batch_normalization_28[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_7 (Conv3DTran  (30, 52, 52, 2, 128  147584     ['activation_37[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)       (30, 52, 52, 2, 256  0           ['activation_31[0][0]',          \n",
      "                                )                                 'conv3d_transpose_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_40 (Conv3D)             (30, 52, 52, 2, 32)  147488      ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (30, 52, 52, 2, 32)  128        ['conv3d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (30, 52, 52, 2, 32)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv3d_41 (Conv3D)             (30, 52, 52, 2, 64)  36928       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (30, 52, 52, 2, 64)  256        ['conv3d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (30, 52, 52, 2, 64)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv3d_transpose_8 (Conv3DTran  (30, 104, 104, 2, 6  36928      ['activation_39[0][0]']          \n",
      " spose)                         4)                                                                \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)       (30, 104, 104, 2, 1  0           ['activation_29[0][0]',          \n",
      "                                28)                               'conv3d_transpose_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_42 (Conv3D)             (30, 104, 104, 2, 1  2305        ['tf.concat_8[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (30, 104, 104, 2, 1  4          ['conv3d_42[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (30, 104, 104, 2, 1  0           ['batch_normalization_31[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_43 (Conv3D)             (30, 104, 104, 2, 3  608         ['activation_40[0][0]']          \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (30, 104, 104, 2, 3  128        ['conv3d_43[0][0]']              \n",
      " ormalization)                  2)                                                                \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (30, 104, 104, 2, 3  0           ['batch_normalization_32[0][0]'] \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_44 (Conv3D)             (30, 104, 104, 2, 1  577         ['activation_41[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,027,750\n",
      "Trainable params: 4,025,892\n",
      "Non-trainable params: 1,858\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 1/5\n",
      "42/42 - 533s - loss: nan - accuracy: 0.8471 - half_mse: nan - val_loss: nan - val_accuracy: 0.9628 - val_half_mse: nan - lr: 6.0000e-04 - 533s/epoch - 13s/step\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 2/5\n",
      "42/42 - 536s - loss: nan - accuracy: 0.9632 - half_mse: nan - val_loss: nan - val_accuracy: 0.9628 - val_half_mse: nan - lr: 6.0000e-04 - 536s/epoch - 13s/step\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [128]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_tracnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [127]\u001B[0m, in \u001B[0;36mtrain_tracnet\u001B[0;34m(dev_set, val_set, input_shape, epochs)\u001B[0m\n\u001B[1;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      7\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mSGD(momentum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m),\n\u001B[1;32m      8\u001B[0m     loss \u001B[38;5;241m=\u001B[39m half_mse,\n\u001B[1;32m      9\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, half_mse],\n\u001B[1;32m     10\u001B[0m     run_eagerly\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     13\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n\u001B[0;32m---> 15\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdev_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mLearningRateScheduler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlr_step_decay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorboard\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\n\u001B[1;32m     22\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# plot accuracy\u001B[39;00m\n\u001B[1;32m     25\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1216\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1210\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1211\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1212\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1213\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1214\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1215\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1216\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1217\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1218\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:878\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_function\u001B[39m(iterator):\n\u001B[1;32m    877\u001B[0m   \u001B[38;5;124;03m\"\"\"Runs a training execution with one step.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstep_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:867\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n\u001B[1;32m    866\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[0;32m--> 867\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    868\u001B[0m outputs \u001B[38;5;241m=\u001B[39m reduce_per_replica(\n\u001B[1;32m    869\u001B[0m     outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    870\u001B[0m write_scalar_summaries(outputs, step\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39m_train_counter)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001B[0m, in \u001B[0;36mStrategyBase.run\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1311\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m   1312\u001B[0m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[1;32m   1313\u001B[0m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[1;32m   1314\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   1315\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1316\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2892\u001B[0m, in \u001B[0;36mStrategyExtendedV1.call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   2890\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   2891\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 2892\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3695\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3693\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[1;32m   3694\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy(), replica_id_in_sync_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m-> 3695\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:601\u001B[0m, in \u001B[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    600\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mControlStatusCtx(status\u001B[38;5;241m=\u001B[39mag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mUNSPECIFIED):\n\u001B[0;32m--> 601\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:860\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    859\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(data):\n\u001B[0;32m--> 860\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    861\u001B[0m   \u001B[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001B[39;00m\n\u001B[1;32m    862\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:816\u001B[0m, in \u001B[0;36mModel.train_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    812\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    813\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTarget data is missing. Your model has `loss`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    814\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand therefore expects target data to be passed in `fit()`.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    815\u001B[0m \u001B[38;5;66;03m# Run backwards pass.\u001B[39;00m\n\u001B[0;32m--> 816\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiled_metrics\u001B[38;5;241m.\u001B[39mupdate_state(y, y_pred, sample_weight)\n\u001B[1;32m    818\u001B[0m \u001B[38;5;66;03m# Collect metrics to return\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:530\u001B[0m, in \u001B[0;36mOptimizerV2.minimize\u001B[0;34m(self, loss, var_list, grad_loss, name, tape)\u001B[0m\n\u001B[1;32m    499\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mminimize\u001B[39m(\u001B[38;5;28mself\u001B[39m, loss, var_list, grad_loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, tape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    500\u001B[0m   \u001B[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001B[39;00m\n\u001B[1;32m    501\u001B[0m \n\u001B[1;32m    502\u001B[0m \u001B[38;5;124;03m  This method simply computes gradient using `tf.GradientTape` and calls\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    528\u001B[0m \n\u001B[1;32m    529\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 530\u001B[0m   grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_gradients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m      \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvar_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    532\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_gradients(grads_and_vars, name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:583\u001B[0m, in \u001B[0;36mOptimizerV2._compute_gradients\u001B[0;34m(self, loss, var_list, grad_loss, tape)\u001B[0m\n\u001B[1;32m    581\u001B[0m var_list \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(var_list)\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mname_scope(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/gradients\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 583\u001B[0m   grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assert_valid_dtypes([\n\u001B[1;32m    586\u001B[0m     v \u001B[38;5;28;01mfor\u001B[39;00m g, v \u001B[38;5;129;01min\u001B[39;00m grads_and_vars\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m g \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m v\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m tf\u001B[38;5;241m.\u001B[39mresource\n\u001B[1;32m    588\u001B[0m ])\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grads_and_vars\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:464\u001B[0m, in \u001B[0;36mOptimizerV2._get_gradients\u001B[0;34m(self, tape, loss, var_list, grad_loss)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_gradients\u001B[39m(\u001B[38;5;28mself\u001B[39m, tape, loss, var_list, grad_loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    463\u001B[0m   \u001B[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 464\u001B[0m   grads \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(grads, var_list))\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1084\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_gradients \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1081\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x)\n\u001B[1;32m   1082\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mflatten(output_gradients)]\n\u001B[0;32m-> 1084\u001B[0m flat_grad \u001B[38;5;241m=\u001B[39m \u001B[43mimperative_grad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimperative_grad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_targets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_sources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1089\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_sources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1090\u001B[0m \u001B[43m    \u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munconnected_gradients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n\u001B[1;32m   1093\u001B[0m   \u001B[38;5;66;03m# Keep track of watched variables before setting tape to None\u001B[39;00m\n\u001B[1;32m   1094\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_watched_variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape\u001B[38;5;241m.\u001B[39mwatched_variables()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:71\u001B[0m, in \u001B[0;36mimperative_grad\u001B[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m     68\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     69\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown value for unconnected_gradients: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m unconnected_gradients)\n\u001B[0;32m---> 71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_TapeGradient\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:159\u001B[0m, in \u001B[0;36m_gradient_function\u001B[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[1;32m    157\u001B[0m     gradient_name_scope \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m forward_pass_name_scope \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    158\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(gradient_name_scope):\n\u001B[0;32m--> 159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmock_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mout_grads\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    161\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m grad_fn(mock_op, \u001B[38;5;241m*\u001B[39mout_grads)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_grad.py:154\u001B[0m, in \u001B[0;36m_Conv3DGrad\u001B[0;34m(op, grad)\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;129m@ops\u001B[39m\u001B[38;5;241m.\u001B[39mRegisterGradient(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConv3D\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Conv3DGrad\u001B[39m(op, grad):\n\u001B[1;32m    152\u001B[0m   data_format \u001B[38;5;241m=\u001B[39m op\u001B[38;5;241m.\u001B[39mget_attr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata_format\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdecode()\n\u001B[1;32m    153\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m--> 154\u001B[0m       \u001B[43mnn_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv3d_backprop_input_v2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m          \u001B[49m\u001B[43marray_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m          \u001B[49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m          \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m          \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_attr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdilations\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m          \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_attr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrides\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m          \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_attr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpadding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m          \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    162\u001B[0m       nn_ops\u001B[38;5;241m.\u001B[39mconv3d_backprop_filter_v2(\n\u001B[1;32m    163\u001B[0m           op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    164\u001B[0m           array_ops\u001B[38;5;241m.\u001B[39mshape(op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m1\u001B[39m]),\n\u001B[1;32m    165\u001B[0m           grad,\n\u001B[1;32m    166\u001B[0m           dilations\u001B[38;5;241m=\u001B[39mop\u001B[38;5;241m.\u001B[39mget_attr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdilations\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    167\u001B[0m           strides\u001B[38;5;241m=\u001B[39mop\u001B[38;5;241m.\u001B[39mget_attr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrides\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    168\u001B[0m           padding\u001B[38;5;241m=\u001B[39mop\u001B[38;5;241m.\u001B[39mget_attr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpadding\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    169\u001B[0m           data_format\u001B[38;5;241m=\u001B[39mdata_format)\n\u001B[1;32m    170\u001B[0m   ]\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:1889\u001B[0m, in \u001B[0;36mconv3d_backprop_input_v2\u001B[0;34m(input_sizes, filter, out_backprop, strides, padding, data_format, dilations, name)\u001B[0m\n\u001B[1;32m   1887\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m   1888\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1889\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mConv3DBackpropInputV2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_sizes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1891\u001B[0m \u001B[43m      \u001B[49m\u001B[43mout_backprop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrides\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpadding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1892\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdilations\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdilations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1893\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   1894\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = train_tracnet(train_dataset, val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0b608",
   "metadata": {},
   "source": [
    "## Error calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60e06c",
   "metadata": {},
   "source": [
    "For a given displacement field, calculate the predicted stress field and the normalized rmse relative to its ground truth for different Young's moduli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19d20bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(path):\n",
    "    errors = []\n",
    "    S = 160\n",
    "    y_moduli = [2500, 5000, 10000, 20000, 400000]\n",
    "    noise = 0.00765\n",
    "    for nr in range(18, 56):\n",
    "        name = f'MLData00{nr}.mat'.format\n",
    "        path = os.path.join(path, name)\n",
    "        if os.path.isfile(path):\n",
    "            cell = [nr]\n",
    "            trac_file = loadmat(path)\n",
    "            brdx = trac_file['brdx']\n",
    "            brdy = trac_file['brdy']\n",
    "            tracGT = trac_file['tracGT']\n",
    "            for i in y_moduli:\n",
    "                name = f'MLData00{nr}-{i}.mat'.format(nr=nr, i=i)\n",
    "                path = os.path.join(path, name)\n",
    "                if os.path.isfile(path):\n",
    "                    dspl_file = loadmat(path)\n",
    "                    dspl = dspl_file['dspl']\n",
    "                    trac = predictTrac(dspl, i)\n",
    "                    err = errorTrac(trac, tracGT, brdx, brdy)\n",
    "                    cell.append(err)\n",
    "\n",
    "                    dspl = addNoise(dspl, noise)\n",
    "                    trac = predictTrac(dspl, i)\n",
    "                    err = errorTrac(trac, tracGT, brdx, brdy)\n",
    "                    cell.append(err)\n",
    "                else:\n",
    "                    continue\n",
    "            errors.append(cell)\n",
    "        else:\n",
    "            continue\n",
    "    df = pd.DataFrame(errors, index=['first', 'second'],\n",
    "                      columns=['File ID', '2,500Pa', '2,500Pa N', '5,000Pa', '5,000Pa N', '10,000Pa', '10,000Pa N',\n",
    "                               '20,000Pa', '20,000Pa N', '40,000Pa', '40,000Pa N'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c7656",
   "metadata": {},
   "source": [
    "`errorTrac` is called by `calcError` to actually perform the error calculation given a predicted stress field and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a43c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorTrac(filepath, filepath_GT, plot=False):\n",
    "    file = loadmat(filepath)  # load prediction\n",
    "    file_GT = loadmat(filepath_GT) # load ground truth\n",
    "    brdx = file['brdx']  # x-values of predicted cell border\n",
    "    brdy = file['brdy']  # y-values of predicted cell border\n",
    "    trac = file['trac']\n",
    "    tracGT = file_GT['trac']\n",
    "    zipped = np.array(list(zip(brdx[0], brdy[0])))  # array with (x,y) pairs of cell border coordinates\n",
    "    polygon = sh.geometry.Polygon(zipped)  # create polygon\n",
    "\n",
    "    interior = np.zeros((file['dspl'].shape[0], file['dspl'].shape[1]), dtype=int)  # create all zero matrix\n",
    "    for i in range(len(interior)):  # set all elements in interior matrix to 1 that actually lie within the cell\n",
    "        for j in range(len(interior[i])):\n",
    "            point = Point(i, j)\n",
    "            if polygon.contains(point):\n",
    "                interior[i][j] = 1\n",
    "\n",
    "    # plot polygons using geopandas\n",
    "    if plot:\n",
    "        p = gpd.GeoSeries(polygon)\n",
    "        p.plot()\n",
    "        plt.show()\n",
    "\n",
    "    # update prediction and ground truth by discarding areas outside of cell borders\n",
    "    trac[:, :, 1] = trac[:, :, 1] * interior\n",
    "    trac[:, :, 2] = trac[:, :, 2] * interior\n",
    "    tracGT[:, :, 1] = tracGT[:, :, 1] * interior\n",
    "    tracGT[:, :, 2] = tracGT[:, :, 2] * interior\n",
    "\n",
    "    # compute rmse\n",
    "    mse = np.sum(np.pow((trac[:, :, 1] - tracGT[:, :, 1], 2)), np.pow((trac[:, :, 2] - tracGT[:, :, 2], 2)))\n",
    "    rmse = np.sqrt(mse)\n",
    "    msm = np.sum(np.pow(tracGT[:, :, 1], 2) + np.pow(tracGT[:, :, 2], 2))\n",
    "    rmsm = np.sqrt(msm)\n",
    "    error = rmse / rmsm\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd94fe9",
   "metadata": {},
   "source": [
    "`add_noise` applies Gaussian noise to a displacement field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dddb582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(dspl, N):\n",
    "    dsplN = np.zeros(shape=dspl.shape)\n",
    "    S = dspl.shape[0]\n",
    "    stdev = N / np.sqrt(2)\n",
    "    noise = np.random.normal(loc=0, scale=stdev, size=(S, S))\n",
    "    dsplN[:, :, 1] = dspl[:, :, 1] + noise\n",
    "    noise = np.random.normal(loc=0, scale=stdev, size=(S, S))\n",
    "    dsplN[:, :, 2] = dspl[:, :, 2] + noise\n",
    "    \n",
    "    return dsplN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}