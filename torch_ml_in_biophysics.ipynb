{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3b4bf4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d812a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f99760",
   "metadata": {},
   "source": [
    "Set seeds for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971573ef",
   "metadata": {},
   "source": [
    "Use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8e804",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79022cda",
   "metadata": {},
   "source": [
    "Specify paths to the training data (104x104 pixel images only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For working on Martinsried machine\n",
    "dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/dspl'\n",
    "dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/dsplRadial'\n",
    "trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/trac'\n",
    "tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dspl'\n",
    "foo_dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dsplRadial'\n",
    "foo_trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_trac'\n",
    "foo_tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For working remotely on CIP machines\n",
    "# dspl_path = '/home/r/richard/Downloads/train/trainData104/dspl'\n",
    "# dsplRadial_path = '/home/r/richard/Downloads/train/trainData104/dsplRadial'\n",
    "# trac_path = '/home/r/richard/Downloads/train/trainData104/trac'\n",
    "# tracRadial_path = '/home/r/richard/Downloads/train/trainData104/tracRadial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77685f13",
   "metadata": {},
   "source": [
    "Load data as `Numpy` arrays first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928b080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f9d88",
   "metadata": {},
   "source": [
    "Create arrays containing 'brdx', 'brdy', 'dspl' or 'trac' and 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "035151f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, dspl_radials, targets, trac_radials = data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path)\n",
    "samples, targets = np.append(samples, dspl_radials), np.append(targets, trac_radials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f700d9",
   "metadata": {},
   "source": [
    "Create arrays for training and validation and specify batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbdbe558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, X and y are of shape (samples, width, height, depth)\n",
    "X, y = np.array([sample['dspl'] for sample in samples]), np.array([target['trac'] for target in targets])\n",
    "# Reshape to (samples, channels, depth, height, width)\n",
    "X = np.moveaxis(X[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y = np.moveaxis(y[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5855b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = X.min(axis=(3, 4), keepdims=True)\n",
    "x_max = X.max(axis=(3, 4), keepdims=True)\n",
    "X = (X - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y.min(axis=(3, 4), keepdims=True)\n",
    "y_max = y.max(axis=(3, 4), keepdims=True)\n",
    "y = (y - y_min)/(y_max-y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7f30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this the same as solution with np.mean??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d46edf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a01797",
   "metadata": {},
   "source": [
    "Create a `DataSet` and `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd44900",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X).double().to(device)\n",
    "X_val = torch.from_numpy(X_val).double().to(device)\n",
    "y_train = torch.from_numpy(y).double().to(device)\n",
    "y_val = torch.from_numpy(y_val).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bdf621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=2 * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b71b01",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca92e5b",
   "metadata": {},
   "source": [
    "Plot displacement of given sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dba659b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDspl(sample):\n",
    "    zipped = np.array(list(zip(sample['brdx'][0], sample['brdy'][0])))  # array with (x,y) pairs of cell border coordinates\n",
    "    polygon = sh.geometry.Polygon(zipped)  # create polygon\n",
    "\n",
    "    interior = np.zeros((sample['dspl'].shape[0], sample['dspl'].shape[1]), dtype=int)  # create all zero matrix\n",
    "    for i in range(len(interior)):  # set all elements in interior matrix to 1 that actually lie within the cell\n",
    "        for j in range(len(interior[i])):\n",
    "            point = Point(i, j)\n",
    "            if polygon.contains(point):\n",
    "                interior[i][j] = 1\n",
    "\n",
    "    # plot polygon using geopandas\n",
    "    p = gpd.GeoSeries(polygon)\n",
    "    p.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386637e",
   "metadata": {},
   "source": [
    "tbd: Plot traction field of given target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "796c3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrac(target):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9519e",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19d6cc",
   "metadata": {},
   "source": [
    "Specify model name and logs for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "760650f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"TracNet104-{}\".format(int(time.time()))\n",
    "# tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47fd1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_1(nn.Module):\n",
    "    \"\"\"Conv3D -> BatchNorm -> ReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76a5c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_2(nn.Module):\n",
    "    \"\"\"Conv3D -> ReLU\"\"\"    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d78457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.s1 = ConvBlock_1(n_channels, 32)\n",
    "        self.s2 = ConvBlock_2(32, 64)\n",
    "        self.s3 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s4 = ConvBlock_1(64, 64)\n",
    "        self.s5 = ConvBlock_2(64, 128)\n",
    "        self.s6 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s7 = ConvBlock_1(128, 128)\n",
    "        self.s8 = ConvBlock_2(128, 256)\n",
    "        self.s9 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s10 = ConvBlock_1(256, 128)\n",
    "        self.s11 = ConvBlock_1(128, 256)\n",
    "        self.s12 = nn.ConvTranspose3d(256, 256, kernel_size=(1, 3, 3), stride=(1,2,2))\n",
    "        #fusion3\n",
    "        self.s13 = ConvBlock_1(512, 64)\n",
    "        self.s14 = ConvBlock_1(64, 128)\n",
    "        self.s15 = nn.ConvTranspose3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion2\n",
    "        self.s16 = ConvBlock_1(256, 32)\n",
    "        self.s17 = ConvBlock_1(32, 64)\n",
    "        self.s18 = nn.ConvTranspose3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion1\n",
    "        self.s19 = ConvBlock_1(128, 1)\n",
    "        self.s20 = ConvBlock_1(1, 32)\n",
    "        self.s21 = nn.Conv3d(32, 1, kernel_size=(2, 3, 3), padding='same')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.s1(x)\n",
    "        x2 = self.s2(x1)\n",
    "        x3 = self.s3(x2)\n",
    "        x4 = self.s4(x3)\n",
    "        x5 = self.s5(x4)\n",
    "        x6 = self.s6(x5)\n",
    "        x7 = self.s7(x6)\n",
    "        x8 = self.s8(x7)\n",
    "        x9 = self.s9(x8)\n",
    "        x10 = self.s10(x9) \n",
    "        x11 = self.s11(x10)\n",
    "        x12 = self.s12(x11)\n",
    "        padded = torch.nn.functional.pad(x12, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion3 = torch.cat((x8, padded), dim=1)\n",
    "        x13 = self.s13(fusion3)\n",
    "        x14 = self.s14(x13)\n",
    "        x15 = self.s15(x14)\n",
    "        padded = torch.nn.functional.pad(x15, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion2 = torch.cat((x5, padded), dim=1)\n",
    "        x16 = self.s16(fusion2)\n",
    "        x17 = self.s17(x16)\n",
    "        x18 = self.s18(x17)\n",
    "        padded = torch.nn.functional.pad(x18, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion1 = torch.cat((x2, padded), dim=1)\n",
    "        x19 = self.s19(fusion1)\n",
    "        x20 = self.s20(x19)\n",
    "        logits = self.s21(x20)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3085f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        nn.init.xavier_normal_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65d48880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_MSE, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "        loss = 0.5 * loss_fn(predictions, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, dataloaders, num_epochs):\n",
    "    model = model.double()\n",
    "    loss_fn = Custom_MSE()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for xb, yb in dataloaders[\"train\"]:\n",
    "            logits = model(xb)\n",
    "            logits = logits.double()     \n",
    "            loss = loss_fn(logits, yb)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(dataloaders[\"train\"])\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dataloaders[\"val\"]:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                logits = model(xb)\n",
    "                logits = logits.double()\n",
    "                loss += loss_fn.forward(logits, yb)\n",
    "            avg_val_loss = loss / len(dataloaders[\"val\"])\n",
    "        #scheduler.step()\n",
    "        print(f\"Epoch {epoch}: train_loss = {avg_train_loss}, test_loss = {avg_val_loss}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TracNet(n_channels=1)\n",
    "print(summary(model, verbose=2))\n",
    "\n",
    "model.apply(initialize_weight)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0000001, momentum=0.9)\n",
    "#scheduler = StepLR(optimizer, step_size=10, gamma=0.000000001)\n",
    "\n",
    "fit(model, optimizer, dataloaders, num_epochs=50)\n",
    "\n",
    "torch.save(model.state_dict(), '/home/alexrichard/LRZ Sync+Share/ML in Physics/model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f55695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = TracNet(n_channels=1).double()\n",
    "model.load_state_dict(torch.load('/home/alexrichard/LRZ Sync+Share/ML in Physics/model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47434348",
   "metadata": {},
   "source": [
    "## Calculate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorTrac(filepath, filepath_GT, plot=False):\n",
    "    \"\"\"Calculate error of traction stress field relative to ground truth as normalized rmse, for cell interior only.\"\"\"\n",
    "    file = loadmat(filepath)  # load prediction\n",
    "    file_GT = loadmat(filepath_GT) # load ground truth\n",
    "    brdx = file['brdx']  # x-values of predicted cell border\n",
    "    brdy = file['brdy']  # y-values of predicted cell border\n",
    "    trac = file['trac']\n",
    "    tracGT = file_GT['trac']\n",
    "    zipped = np.array(list(zip(brdx[0], brdy[0])))  # array with (x,y) pairs of cell border coordinates\n",
    "    polygon = sh.geometry.Polygon(zipped)  # create polygon\n",
    "\n",
    "    interior = np.zeros((file['dspl'].shape[0], file['dspl'].shape[1]), dtype=int)  # create all zero matrix\n",
    "    for i in range(len(interior)):  # set all elements in interior matrix to 1 that actually lie within the cell\n",
    "        for j in range(len(interior[i])):\n",
    "            point = Point(i, j)\n",
    "            if polygon.contains(point):\n",
    "                interior[i][j] = 1\n",
    "\n",
    "    # plot polygons using geopandas\n",
    "    if plot:\n",
    "        p = gpd.GeoSeries(polygon)\n",
    "        p.plot()\n",
    "        plt.show()\n",
    "\n",
    "    # update prediction and ground truth by discarding areas outside of cell borders\n",
    "    trac[:, :, 1] = trac[:, :, 1] * interior\n",
    "    trac[:, :, 2] = trac[:, :, 2] * interior\n",
    "    tracGT[:, :, 1] = tracGT[:, :, 1] * interior\n",
    "    tracGT[:, :, 2] = tracGT[:, :, 2] * interior\n",
    "\n",
    "    # compute rmse\n",
    "    mse = np.sum(np.pow((trac[:, :, 1] - tracGT[:, :, 1], 2)), np.pow((trac[:, :, 2] - tracGT[:, :, 2], 2)))\n",
    "    rmse = np.sqrt(mse)\n",
    "    msm = np.sum(np.pow(tracGT[:, :, 1], 2) + np.pow(tracGT[:, :, 2], 2))\n",
    "    rmsm = np.sqrt(msm)\n",
    "    error = rmse / rmsm\n",
    "\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9952206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for working on Martinsried machine\n",
    "sample_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/test/generic/testData104/dspl/MLData0022.mat'\n",
    "target_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/test/generic/testData104/trac/MLData0022.mat'\n",
    "sample = loadmat(sample_path)\n",
    "target = loadmat(target_path)\n",
    "dspl_field = np.array(sample['dspl'])[np.newaxis, :]\n",
    "trac_field = np.array(target['trac'])[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62c2bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/trac/MLData001-00.mat')['trac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71dfc861",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trac_field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [60]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m np\u001B[38;5;241m.\u001B[39mallclose(ground_truth, \u001B[43mtrac_field\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trac_field' is not defined"
     ]
    }
   ],
   "source": [
    "np.allclose(ground_truth, trac_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44eeb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_prediction = torch.from_numpy(matlab_prediction).double().to(device)\n",
    "ground_truth = torch.from_numpy(ground_truth).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4bfd2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictions, target):\n",
    "    loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "    loss = 0.5 * loss_fn(predictions, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1dd6b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6059, dtype=torch.float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(matlab_prediction, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e09bc28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dspl_field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [49]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dspl_field \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmoveaxis(\u001B[43mdspl_field\u001B[49m[:, np\u001B[38;5;241m.\u001B[39mnewaxis], [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m], [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m      2\u001B[0m trac_field \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmoveaxis(trac_field[:, np\u001B[38;5;241m.\u001B[39mnewaxis], [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m], [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m2\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dspl_field' is not defined"
     ]
    }
   ],
   "source": [
    "dspl_field = np.moveaxis(dspl_field[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "trac_field = np.moveaxis(trac_field[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ee67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl_field = torch.from_numpy(dspl_field).double()\n",
    "trac_field = torch.from_numpy(trac_field).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    with torch.no_grad():\n",
    "        return model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e030d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(dspl_field)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}