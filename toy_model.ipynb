{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73abdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5decf",
   "metadata": {},
   "source": [
    "Set seeds for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35207a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd2871",
   "metadata": {},
   "source": [
    "Use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dspl'\n",
    "foo_dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dsplRadial'\n",
    "foo_trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_trac'\n",
    "foo_tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, dspl_radials, targets, trac_radials = data_to_npArrays(foo_dspl_path, foo_dsplRadial_path, foo_trac_path, foo_tracRadial_path)\n",
    "#samples, targets = np.append(samples, dspl_radials), np.append(targets, trac_radials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b222d",
   "metadata": {},
   "source": [
    "Compute loss between sample and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f68b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, X and y are of shape (samples, width, height, depth)\n",
    "X, y = np.array([sample['dspl'] for sample in samples]), np.array([target['trac'] for target in targets])\n",
    "# Reshape to (samples, channels, depth, height, width)\n",
    "X = np.moveaxis(X[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y = np.moveaxis(y[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add172fc",
   "metadata": {},
   "source": [
    "Normalize train and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed26db7",
   "metadata": {},
   "source": [
    "x_min = X.min(axis=(3, 4), keepdims=True)\n",
    "x_max = X.max(axis=(3, 4), keepdims=True)\n",
    "\n",
    "X = (X - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y.min(axis=(3, 4), keepdims=True)\n",
    "y_max = y.max(axis=(3, 4), keepdims=True)\n",
    "\n",
    "y = (y - y_min)/(y_max-y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X).double().to(device)\n",
    "X_val = torch.from_numpy(X_val).double().to(device)\n",
    "y_train = torch.from_numpy(y).double().to(device)\n",
    "y_val = torch.from_numpy(y_val).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac94f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=2 * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ae588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_1(nn.Module):\n",
    "    \"\"\"Conv3D -> BatchNorm -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_2(nn.Module):\n",
    "    \"\"\"Conv3D -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1865b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.s1 = ConvBlock_1(n_channels, 32)\n",
    "        self.s2 = ConvBlock_2(32, 64)\n",
    "        self.s3 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s4 = ConvBlock_1(64, 64)\n",
    "        self.s5 = ConvBlock_2(64, 128)\n",
    "        self.s6 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s7 = ConvBlock_1(128, 128)\n",
    "        self.s8 = ConvBlock_2(128, 256)\n",
    "        self.s9 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s10 = ConvBlock_1(256, 128)\n",
    "        self.s11 = ConvBlock_1(128, 256)\n",
    "        self.s12 = nn.ConvTranspose3d(256, 256, kernel_size=(1, 3, 3), stride=(1,2,2))\n",
    "        #fusion3\n",
    "        self.s13 = ConvBlock_1(512, 64)\n",
    "        self.s14 = ConvBlock_1(64, 128)\n",
    "        self.s15 = nn.ConvTranspose3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion2\n",
    "        self.s16 = ConvBlock_1(256, 32)\n",
    "        self.s17 = ConvBlock_1(32, 64)\n",
    "        self.s18 = nn.ConvTranspose3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion1\n",
    "        self.s19 = ConvBlock_1(128, 1)\n",
    "        self.s20 = ConvBlock_1(1, 32)\n",
    "        self.s21 = nn.Conv3d(32, 1, kernel_size=(2, 3, 3), padding='same')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.s1(x)\n",
    "        x2 = self.s2(x1)\n",
    "        x3 = self.s3(x2)\n",
    "        x4 = self.s4(x3)\n",
    "        x5 = self.s5(x4)\n",
    "        x6 = self.s6(x5)\n",
    "        x7 = self.s7(x6)\n",
    "        x8 = self.s8(x7)\n",
    "        x9 = self.s9(x8)\n",
    "        x10 = self.s10(x9) \n",
    "        x11 = self.s11(x10)\n",
    "        x12 = self.s12(x11)\n",
    "        padded = torch.nn.functional.pad(x12, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion3 = torch.cat((x8, padded), dim=1)\n",
    "        x13 = self.s13(fusion3)\n",
    "        x14 = self.s14(x13)\n",
    "        x15 = self.s15(x14)\n",
    "        padded = torch.nn.functional.pad(x15, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion2 = torch.cat((x5, padded), dim=1)\n",
    "        x16 = self.s16(fusion2)\n",
    "        x17 = self.s17(x16)\n",
    "        x18 = self.s18(x17)\n",
    "        padded = torch.nn.functional.pad(x18, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion1 = torch.cat((x2, padded), dim=1)\n",
    "        x19 = self.s19(fusion1)\n",
    "        x20 = self.s20(x19)\n",
    "        logits = self.s21(x20)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa126d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        nn.init.xavier_normal_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_MSE, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "        loss = 0.5 * loss_fn(predictions, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, dataloaders, num_epochs):\n",
    "    model = model.double()\n",
    "    loss_fn = Custom_MSE()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for xb, yb in dataloaders[\"train\"]:\n",
    "            logits = model(xb)\n",
    "            logits = logits.double()     \n",
    "            loss = loss_fn(logits, yb)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(dataloaders[\"train\"])\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dataloaders[\"val\"]:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                logits = model(xb)\n",
    "                logits = logits.double()\n",
    "                loss += loss_fn.forward(logits, yb)\n",
    "            avg_val_loss = loss / len(dataloaders[\"val\"])\n",
    "        #scheduler.step()\n",
    "        print(f\"Epoch {epoch}: train_loss = {avg_train_loss}, test_loss = {avg_val_loss}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81a64a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = TracNet(n_channels=1)\n",
    "print(summary(model, verbose=2))\n",
    "\n",
    "model.apply(initialize_weight)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0000006, momentum=0.9)\n",
    "#scheduler = StepLR(optimizer, step_size=10, gamma=0.7943)\n",
    "\n",
    "fit(model, optimizer, dataloaders, num_epochs=20000)\n",
    "\n",
    "torch.save(model.state_dict(), '/home/alexrichard/LRZ Sync+Share/ML in Physics/toy_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7feddc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = TracNet(n_channels=1).double()\n",
    "model.load_state_dict(torch.load('/home/alexrichard/LRZ Sync+Share/ML in Physics/toy_model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdb734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test data for working on Martinsried machine\n",
    "test_sample = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dspl/MLData001-00.mat')['dspl'])\n",
    "test_target = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_trac/MLData001-00.mat')['trac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = torch.from_numpy(test_sample).double().to(device)\n",
    "test_target = torch.from_numpy(test_target).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6796077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    with torch.no_grad():\n",
    "        return model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be57e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_prediction = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/prediction.mat')['ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f41cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/trac/MLData001-00.mat')['trac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = torch.from_numpy(ground_truth).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b84933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictions, target):\n",
    "    loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "    loss = 0.5 * loss_fn(predictions, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7556c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(ground_truth, trac_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee57ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
