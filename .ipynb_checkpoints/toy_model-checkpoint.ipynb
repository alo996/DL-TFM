{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73abdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5decf",
   "metadata": {},
   "source": [
    "Set seeds for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35207a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd2871",
   "metadata": {},
   "source": [
    "Use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daba7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ead603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dspl'\n",
    "foo_dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dsplRadial'\n",
    "foo_trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_trac'\n",
    "foo_tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50e0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a7f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, dspl_radials, targets, trac_radials = data_to_npArrays(foo_dspl_path, foo_dsplRadial_path, foo_trac_path, foo_tracRadial_path)\n",
    "#samples, targets = np.append(samples, dspl_radials), np.append(targets, trac_radials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d085a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b79b222d",
   "metadata": {},
   "source": [
    "Compute loss between sample and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f68b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, X and y are of shape (samples, width, height, depth)\n",
    "X, y = np.array([sample['dspl'] for sample in samples]), np.array([target['trac'] for target in targets])\n",
    "# Reshape to (samples, channels, depth, height, width)\n",
    "X = np.moveaxis(X[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y = np.moveaxis(y[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a64e8d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 2, 104, 104)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add172fc",
   "metadata": {},
   "source": [
    "Normalize train and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7742e",
   "metadata": {},
   "source": [
    "x_min = X.min(axis=(3, 4), keepdims=True)\n",
    "x_max = X.max(axis=(3, 4), keepdims=True)\n",
    "\n",
    "X = (X - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y.min(axis=(3, 4), keepdims=True)\n",
    "y_max = y.max(axis=(3, 4), keepdims=True)\n",
    "\n",
    "y = (y - y_min)/(y_max-y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95cf2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73f3c899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 2, 104, 104)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e32b01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2, 104, 104)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57aa8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X).double().to(device)\n",
    "X_val = torch.from_numpy(X_val).double().to(device)\n",
    "y_train = torch.from_numpy(y).double().to(device)\n",
    "y_val = torch.from_numpy(y_val).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dac94f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=2 * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59ae588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_1(nn.Module):\n",
    "    \"\"\"Conv3D -> BatchNorm -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0159c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_2(nn.Module):\n",
    "    \"\"\"Conv3D -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1865b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.s1 = ConvBlock_1(n_channels, 32)\n",
    "        self.s2 = ConvBlock_2(32, 64)\n",
    "        self.s3 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s4 = ConvBlock_1(64, 64)\n",
    "        self.s5 = ConvBlock_2(64, 128)\n",
    "        self.s6 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s7 = ConvBlock_1(128, 128)\n",
    "        self.s8 = ConvBlock_2(128, 256)\n",
    "        self.s9 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s10 = ConvBlock_1(256, 128)\n",
    "        self.s11 = ConvBlock_1(128, 256)\n",
    "        self.s12 = nn.ConvTranspose3d(256, 256, kernel_size=(1, 3, 3), stride=(1,2,2))\n",
    "        #fusion3\n",
    "        self.s13 = ConvBlock_1(512, 64)\n",
    "        self.s14 = ConvBlock_1(64, 128)\n",
    "        self.s15 = nn.ConvTranspose3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion2\n",
    "        self.s16 = ConvBlock_1(256, 32)\n",
    "        self.s17 = ConvBlock_1(32, 64)\n",
    "        self.s18 = nn.ConvTranspose3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion1\n",
    "        self.s19 = ConvBlock_1(128, 1)\n",
    "        self.s20 = ConvBlock_1(1, 32)\n",
    "        self.s21 = nn.Conv3d(32, 1, kernel_size=(2, 3, 3), padding='same')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.s1(x)\n",
    "        x2 = self.s2(x1)\n",
    "        x3 = self.s3(x2)\n",
    "        x4 = self.s4(x3)\n",
    "        x5 = self.s5(x4)\n",
    "        x6 = self.s6(x5)\n",
    "        x7 = self.s7(x6)\n",
    "        x8 = self.s8(x7)\n",
    "        x9 = self.s9(x8)\n",
    "        x10 = self.s10(x9) \n",
    "        x11 = self.s11(x10)\n",
    "        x12 = self.s12(x11)\n",
    "        padded = torch.nn.functional.pad(x12, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion3 = torch.cat((x8, padded), dim=1)\n",
    "        x13 = self.s13(fusion3)\n",
    "        x14 = self.s14(x13)\n",
    "        x15 = self.s15(x14)\n",
    "        padded = torch.nn.functional.pad(x15, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion2 = torch.cat((x5, padded), dim=1)\n",
    "        x16 = self.s16(fusion2)\n",
    "        x17 = self.s17(x16)\n",
    "        x18 = self.s18(x17)\n",
    "        padded = torch.nn.functional.pad(x18, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion1 = torch.cat((x2, padded), dim=1)\n",
    "        x19 = self.s19(fusion1)\n",
    "        x20 = self.s20(x19)\n",
    "        logits = self.s21(x20)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa126d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        nn.init.xavier_normal_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "453e6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_MSE, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "        loss = 0.5 * loss_fn(predictions, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cecaadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, dataloaders, num_epochs):\n",
    "    model = model.double()\n",
    "    loss_fn = Custom_MSE()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for xb, yb in dataloaders[\"train\"]:\n",
    "            logits = model(xb)\n",
    "            logits = logits.double()     \n",
    "            loss = loss_fn(logits, yb)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(dataloaders[\"train\"])\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dataloaders[\"val\"]:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                logits = model(xb)\n",
    "                logits = logits.double()\n",
    "                loss += loss_fn.forward(logits, yb)\n",
    "            avg_val_loss = loss / len(dataloaders[\"val\"])\n",
    "        #scheduler.step()\n",
    "        print(f\"Epoch {epoch}: train_loss = {avg_train_loss}, test_loss = {avg_val_loss}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df81a64a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "TracNet                                  --\n",
      "├─ConvBlock_1: 1-1                       --\n",
      "│    └─conv_block_1.0.weight             ├─576\n",
      "│    └─conv_block_1.0.bias               ├─32\n",
      "│    └─conv_block_1.1.weight             ├─32\n",
      "│    └─conv_block_1.1.bias               └─32\n",
      "│    └─Sequential: 2-1                   --\n",
      "│    │    └─0.weight                     ├─576\n",
      "│    │    └─0.bias                       ├─32\n",
      "│    │    └─1.weight                     ├─32\n",
      "│    │    └─1.bias                       └─32\n",
      "│    │    └─Conv3d: 3-1                  608\n",
      "│    │    │    └─weight                  ├─576\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─BatchNorm3d: 3-2             64\n",
      "│    │    │    └─weight                  ├─32\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─ReLU: 3-3                    --\n",
      "├─ConvBlock_2: 1-2                       --\n",
      "│    └─conv_block_2.0.weight             ├─36,864\n",
      "│    └─conv_block_2.0.bias               └─64\n",
      "│    └─Sequential: 2-2                   --\n",
      "│    │    └─0.weight                     ├─36,864\n",
      "│    │    └─0.bias                       └─64\n",
      "│    │    └─Conv3d: 3-4                  36,928\n",
      "│    │    │    └─weight                  ├─36,864\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-5                    --\n",
      "├─MaxPool3d: 1-3                         --\n",
      "├─ConvBlock_1: 1-4                       --\n",
      "│    └─conv_block_1.0.weight             ├─73,728\n",
      "│    └─conv_block_1.0.bias               ├─64\n",
      "│    └─conv_block_1.1.weight             ├─64\n",
      "│    └─conv_block_1.1.bias               └─64\n",
      "│    └─Sequential: 2-3                   --\n",
      "│    │    └─0.weight                     ├─73,728\n",
      "│    │    └─0.bias                       ├─64\n",
      "│    │    └─1.weight                     ├─64\n",
      "│    │    └─1.bias                       └─64\n",
      "│    │    └─Conv3d: 3-6                  73,792\n",
      "│    │    │    └─weight                  ├─73,728\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─BatchNorm3d: 3-7             128\n",
      "│    │    │    └─weight                  ├─64\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-8                    --\n",
      "├─ConvBlock_2: 1-5                       --\n",
      "│    └─conv_block_2.0.weight             ├─147,456\n",
      "│    └─conv_block_2.0.bias               └─128\n",
      "│    └─Sequential: 2-4                   --\n",
      "│    │    └─0.weight                     ├─147,456\n",
      "│    │    └─0.bias                       └─128\n",
      "│    │    └─Conv3d: 3-9                  147,584\n",
      "│    │    │    └─weight                  ├─147,456\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-10                   --\n",
      "├─MaxPool3d: 1-6                         --\n",
      "├─ConvBlock_1: 1-7                       --\n",
      "│    └─conv_block_1.0.weight             ├─294,912\n",
      "│    └─conv_block_1.0.bias               ├─128\n",
      "│    └─conv_block_1.1.weight             ├─128\n",
      "│    └─conv_block_1.1.bias               └─128\n",
      "│    └─Sequential: 2-5                   --\n",
      "│    │    └─0.weight                     ├─294,912\n",
      "│    │    └─0.bias                       ├─128\n",
      "│    │    └─1.weight                     ├─128\n",
      "│    │    └─1.bias                       └─128\n",
      "│    │    └─Conv3d: 3-11                 295,040\n",
      "│    │    │    └─weight                  ├─294,912\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─BatchNorm3d: 3-12            256\n",
      "│    │    │    └─weight                  ├─128\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-13                   --\n",
      "├─ConvBlock_2: 1-8                       --\n",
      "│    └─conv_block_2.0.weight             ├─589,824\n",
      "│    └─conv_block_2.0.bias               └─256\n",
      "│    └─Sequential: 2-6                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       └─256\n",
      "│    │    └─Conv3d: 3-14                 590,080\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─256\n",
      "│    │    └─ReLU: 3-15                   --\n",
      "├─MaxPool3d: 1-9                         --\n",
      "├─ConvBlock_1: 1-10                      --\n",
      "│    └─conv_block_1.0.weight             ├─589,824\n",
      "│    └─conv_block_1.0.bias               ├─128\n",
      "│    └─conv_block_1.1.weight             ├─128\n",
      "│    └─conv_block_1.1.bias               └─128\n",
      "│    └─Sequential: 2-7                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       ├─128\n",
      "│    │    └─1.weight                     ├─128\n",
      "│    │    └─1.bias                       └─128\n",
      "│    │    └─Conv3d: 3-16                 589,952\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─BatchNorm3d: 3-17            256\n",
      "│    │    │    └─weight                  ├─128\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-18                   --\n",
      "├─ConvBlock_1: 1-11                      --\n",
      "│    └─conv_block_1.0.weight             ├─589,824\n",
      "│    └─conv_block_1.0.bias               ├─256\n",
      "│    └─conv_block_1.1.weight             ├─256\n",
      "│    └─conv_block_1.1.bias               └─256\n",
      "│    └─Sequential: 2-8                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       ├─256\n",
      "│    │    └─1.weight                     ├─256\n",
      "│    │    └─1.bias                       └─256\n",
      "│    │    └─Conv3d: 3-19                 590,080\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─256\n",
      "│    │    └─BatchNorm3d: 3-20            512\n",
      "│    │    │    └─weight                  ├─256\n",
      "│    │    │    └─bias                    └─256\n",
      "│    │    └─ReLU: 3-21                   --\n",
      "├─ConvTranspose3d: 1-12                  590,080\n",
      "│    └─weight                            ├─589,824\n",
      "│    └─bias                              └─256\n",
      "├─ConvBlock_1: 1-13                      --\n",
      "│    └─conv_block_1.0.weight             ├─589,824\n",
      "│    └─conv_block_1.0.bias               ├─64\n",
      "│    └─conv_block_1.1.weight             ├─64\n",
      "│    └─conv_block_1.1.bias               └─64\n",
      "│    └─Sequential: 2-9                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       ├─64\n",
      "│    │    └─1.weight                     ├─64\n",
      "│    │    └─1.bias                       └─64\n",
      "│    │    └─Conv3d: 3-22                 589,888\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─BatchNorm3d: 3-23            128\n",
      "│    │    │    └─weight                  ├─64\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-24                   --\n",
      "├─ConvBlock_1: 1-14                      --\n",
      "│    └─conv_block_1.0.weight             ├─147,456\n",
      "│    └─conv_block_1.0.bias               ├─128\n",
      "│    └─conv_block_1.1.weight             ├─128\n",
      "│    └─conv_block_1.1.bias               └─128\n",
      "│    └─Sequential: 2-10                  --\n",
      "│    │    └─0.weight                     ├─147,456\n",
      "│    │    └─0.bias                       ├─128\n",
      "│    │    └─1.weight                     ├─128\n",
      "│    │    └─1.bias                       └─128\n",
      "│    │    └─Conv3d: 3-25                 147,584\n",
      "│    │    │    └─weight                  ├─147,456\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─BatchNorm3d: 3-26            256\n",
      "│    │    │    └─weight                  ├─128\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-27                   --\n",
      "├─ConvTranspose3d: 1-15                  147,584\n",
      "│    └─weight                            ├─147,456\n",
      "│    └─bias                              └─128\n",
      "├─ConvBlock_1: 1-16                      --\n",
      "│    └─conv_block_1.0.weight             ├─147,456\n",
      "│    └─conv_block_1.0.bias               ├─32\n",
      "│    └─conv_block_1.1.weight             ├─32\n",
      "│    └─conv_block_1.1.bias               └─32\n",
      "│    └─Sequential: 2-11                  --\n",
      "│    │    └─0.weight                     ├─147,456\n",
      "│    │    └─0.bias                       ├─32\n",
      "│    │    └─1.weight                     ├─32\n",
      "│    │    └─1.bias                       └─32\n",
      "│    │    └─Conv3d: 3-28                 147,488\n",
      "│    │    │    └─weight                  ├─147,456\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─BatchNorm3d: 3-29            64\n",
      "│    │    │    └─weight                  ├─32\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─ReLU: 3-30                   --\n",
      "├─ConvBlock_1: 1-17                      --\n",
      "│    └─conv_block_1.0.weight             ├─36,864\n",
      "│    └─conv_block_1.0.bias               ├─64\n",
      "│    └─conv_block_1.1.weight             ├─64\n",
      "│    └─conv_block_1.1.bias               └─64\n",
      "│    └─Sequential: 2-12                  --\n",
      "│    │    └─0.weight                     ├─36,864\n",
      "│    │    └─0.bias                       ├─64\n",
      "│    │    └─1.weight                     ├─64\n",
      "│    │    └─1.bias                       └─64\n",
      "│    │    └─Conv3d: 3-31                 36,928\n",
      "│    │    │    └─weight                  ├─36,864\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─BatchNorm3d: 3-32            128\n",
      "│    │    │    └─weight                  ├─64\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-33                   --\n",
      "├─ConvTranspose3d: 1-18                  36,928\n",
      "│    └─weight                            ├─36,864\n",
      "│    └─bias                              └─64\n",
      "├─ConvBlock_1: 1-19                      --\n",
      "│    └─conv_block_1.0.weight             ├─2,304\n",
      "│    └─conv_block_1.0.bias               ├─1\n",
      "│    └─conv_block_1.1.weight             ├─1\n",
      "│    └─conv_block_1.1.bias               └─1\n",
      "│    └─Sequential: 2-13                  --\n",
      "│    │    └─0.weight                     ├─2,304\n",
      "│    │    └─0.bias                       ├─1\n",
      "│    │    └─1.weight                     ├─1\n",
      "│    │    └─1.bias                       └─1\n",
      "│    │    └─Conv3d: 3-34                 2,305\n",
      "│    │    │    └─weight                  ├─2,304\n",
      "│    │    │    └─bias                    └─1\n",
      "│    │    └─BatchNorm3d: 3-35            2\n",
      "│    │    │    └─weight                  ├─1\n",
      "│    │    │    └─bias                    └─1\n",
      "│    │    └─ReLU: 3-36                   --\n",
      "├─ConvBlock_1: 1-20                      --\n",
      "│    └─conv_block_1.0.weight             ├─576\n",
      "│    └─conv_block_1.0.bias               ├─32\n",
      "│    └─conv_block_1.1.weight             ├─32\n",
      "│    └─conv_block_1.1.bias               └─32\n",
      "│    └─Sequential: 2-14                  --\n",
      "│    │    └─0.weight                     ├─576\n",
      "│    │    └─0.bias                       ├─32\n",
      "│    │    └─1.weight                     ├─32\n",
      "│    │    └─1.bias                       └─32\n",
      "│    │    └─Conv3d: 3-37                 608\n",
      "│    │    │    └─weight                  ├─576\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─BatchNorm3d: 3-38            64\n",
      "│    │    │    └─weight                  ├─32\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─ReLU: 3-39                   --\n",
      "├─Conv3d: 1-21                           577\n",
      "│    └─weight                            ├─576\n",
      "│    └─bias                              └─1\n",
      "=================================================================\n",
      "Total params: 4,025,892\n",
      "Trainable params: 4,025,892\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "TracNet                                  --\n",
      "├─ConvBlock_1: 1-1                       --\n",
      "│    └─conv_block_1.0.weight             ├─576\n",
      "│    └─conv_block_1.0.bias               ├─32\n",
      "│    └─conv_block_1.1.weight             ├─32\n",
      "│    └─conv_block_1.1.bias               └─32\n",
      "│    └─Sequential: 2-1                   --\n",
      "│    │    └─0.weight                     ├─576\n",
      "│    │    └─0.bias                       ├─32\n",
      "│    │    └─1.weight                     ├─32\n",
      "│    │    └─1.bias                       └─32\n",
      "│    │    └─Conv3d: 3-1                  608\n",
      "│    │    │    └─weight                  ├─576\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─BatchNorm3d: 3-2             64\n",
      "│    │    │    └─weight                  ├─32\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─ReLU: 3-3                    --\n",
      "├─ConvBlock_2: 1-2                       --\n",
      "│    └─conv_block_2.0.weight             ├─36,864\n",
      "│    └─conv_block_2.0.bias               └─64\n",
      "│    └─Sequential: 2-2                   --\n",
      "│    │    └─0.weight                     ├─36,864\n",
      "│    │    └─0.bias                       └─64\n",
      "│    │    └─Conv3d: 3-4                  36,928\n",
      "│    │    │    └─weight                  ├─36,864\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-5                    --\n",
      "├─MaxPool3d: 1-3                         --\n",
      "├─ConvBlock_1: 1-4                       --\n",
      "│    └─conv_block_1.0.weight             ├─73,728\n",
      "│    └─conv_block_1.0.bias               ├─64\n",
      "│    └─conv_block_1.1.weight             ├─64\n",
      "│    └─conv_block_1.1.bias               └─64\n",
      "│    └─Sequential: 2-3                   --\n",
      "│    │    └─0.weight                     ├─73,728\n",
      "│    │    └─0.bias                       ├─64\n",
      "│    │    └─1.weight                     ├─64\n",
      "│    │    └─1.bias                       └─64\n",
      "│    │    └─Conv3d: 3-6                  73,792\n",
      "│    │    │    └─weight                  ├─73,728\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─BatchNorm3d: 3-7             128\n",
      "│    │    │    └─weight                  ├─64\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-8                    --\n",
      "├─ConvBlock_2: 1-5                       --\n",
      "│    └─conv_block_2.0.weight             ├─147,456\n",
      "│    └─conv_block_2.0.bias               └─128\n",
      "│    └─Sequential: 2-4                   --\n",
      "│    │    └─0.weight                     ├─147,456\n",
      "│    │    └─0.bias                       └─128\n",
      "│    │    └─Conv3d: 3-9                  147,584\n",
      "│    │    │    └─weight                  ├─147,456\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-10                   --\n",
      "├─MaxPool3d: 1-6                         --\n",
      "├─ConvBlock_1: 1-7                       --\n",
      "│    └─conv_block_1.0.weight             ├─294,912\n",
      "│    └─conv_block_1.0.bias               ├─128\n",
      "│    └─conv_block_1.1.weight             ├─128\n",
      "│    └─conv_block_1.1.bias               └─128\n",
      "│    └─Sequential: 2-5                   --\n",
      "│    │    └─0.weight                     ├─294,912\n",
      "│    │    └─0.bias                       ├─128\n",
      "│    │    └─1.weight                     ├─128\n",
      "│    │    └─1.bias                       └─128\n",
      "│    │    └─Conv3d: 3-11                 295,040\n",
      "│    │    │    └─weight                  ├─294,912\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─BatchNorm3d: 3-12            256\n",
      "│    │    │    └─weight                  ├─128\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-13                   --\n",
      "├─ConvBlock_2: 1-8                       --\n",
      "│    └─conv_block_2.0.weight             ├─589,824\n",
      "│    └─conv_block_2.0.bias               └─256\n",
      "│    └─Sequential: 2-6                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       └─256\n",
      "│    │    └─Conv3d: 3-14                 590,080\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─256\n",
      "│    │    └─ReLU: 3-15                   --\n",
      "├─MaxPool3d: 1-9                         --\n",
      "├─ConvBlock_1: 1-10                      --\n",
      "│    └─conv_block_1.0.weight             ├─589,824\n",
      "│    └─conv_block_1.0.bias               ├─128\n",
      "│    └─conv_block_1.1.weight             ├─128\n",
      "│    └─conv_block_1.1.bias               └─128\n",
      "│    └─Sequential: 2-7                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       ├─128\n",
      "│    │    └─1.weight                     ├─128\n",
      "│    │    └─1.bias                       └─128\n",
      "│    │    └─Conv3d: 3-16                 589,952\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─BatchNorm3d: 3-17            256\n",
      "│    │    │    └─weight                  ├─128\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-18                   --\n",
      "├─ConvBlock_1: 1-11                      --\n",
      "│    └─conv_block_1.0.weight             ├─589,824\n",
      "│    └─conv_block_1.0.bias               ├─256\n",
      "│    └─conv_block_1.1.weight             ├─256\n",
      "│    └─conv_block_1.1.bias               └─256\n",
      "│    └─Sequential: 2-8                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       ├─256\n",
      "│    │    └─1.weight                     ├─256\n",
      "│    │    └─1.bias                       └─256\n",
      "│    │    └─Conv3d: 3-19                 590,080\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─256\n",
      "│    │    └─BatchNorm3d: 3-20            512\n",
      "│    │    │    └─weight                  ├─256\n",
      "│    │    │    └─bias                    └─256\n",
      "│    │    └─ReLU: 3-21                   --\n",
      "├─ConvTranspose3d: 1-12                  590,080\n",
      "│    └─weight                            ├─589,824\n",
      "│    └─bias                              └─256\n",
      "├─ConvBlock_1: 1-13                      --\n",
      "│    └─conv_block_1.0.weight             ├─589,824\n",
      "│    └─conv_block_1.0.bias               ├─64\n",
      "│    └─conv_block_1.1.weight             ├─64\n",
      "│    └─conv_block_1.1.bias               └─64\n",
      "│    └─Sequential: 2-9                   --\n",
      "│    │    └─0.weight                     ├─589,824\n",
      "│    │    └─0.bias                       ├─64\n",
      "│    │    └─1.weight                     ├─64\n",
      "│    │    └─1.bias                       └─64\n",
      "│    │    └─Conv3d: 3-22                 589,888\n",
      "│    │    │    └─weight                  ├─589,824\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─BatchNorm3d: 3-23            128\n",
      "│    │    │    └─weight                  ├─64\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-24                   --\n",
      "├─ConvBlock_1: 1-14                      --\n",
      "│    └─conv_block_1.0.weight             ├─147,456\n",
      "│    └─conv_block_1.0.bias               ├─128\n",
      "│    └─conv_block_1.1.weight             ├─128\n",
      "│    └─conv_block_1.1.bias               └─128\n",
      "│    └─Sequential: 2-10                  --\n",
      "│    │    └─0.weight                     ├─147,456\n",
      "│    │    └─0.bias                       ├─128\n",
      "│    │    └─1.weight                     ├─128\n",
      "│    │    └─1.bias                       └─128\n",
      "│    │    └─Conv3d: 3-25                 147,584\n",
      "│    │    │    └─weight                  ├─147,456\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─BatchNorm3d: 3-26            256\n",
      "│    │    │    └─weight                  ├─128\n",
      "│    │    │    └─bias                    └─128\n",
      "│    │    └─ReLU: 3-27                   --\n",
      "├─ConvTranspose3d: 1-15                  147,584\n",
      "│    └─weight                            ├─147,456\n",
      "│    └─bias                              └─128\n",
      "├─ConvBlock_1: 1-16                      --\n",
      "│    └─conv_block_1.0.weight             ├─147,456\n",
      "│    └─conv_block_1.0.bias               ├─32\n",
      "│    └─conv_block_1.1.weight             ├─32\n",
      "│    └─conv_block_1.1.bias               └─32\n",
      "│    └─Sequential: 2-11                  --\n",
      "│    │    └─0.weight                     ├─147,456\n",
      "│    │    └─0.bias                       ├─32\n",
      "│    │    └─1.weight                     ├─32\n",
      "│    │    └─1.bias                       └─32\n",
      "│    │    └─Conv3d: 3-28                 147,488\n",
      "│    │    │    └─weight                  ├─147,456\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─BatchNorm3d: 3-29            64\n",
      "│    │    │    └─weight                  ├─32\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─ReLU: 3-30                   --\n",
      "├─ConvBlock_1: 1-17                      --\n",
      "│    └─conv_block_1.0.weight             ├─36,864\n",
      "│    └─conv_block_1.0.bias               ├─64\n",
      "│    └─conv_block_1.1.weight             ├─64\n",
      "│    └─conv_block_1.1.bias               └─64\n",
      "│    └─Sequential: 2-12                  --\n",
      "│    │    └─0.weight                     ├─36,864\n",
      "│    │    └─0.bias                       ├─64\n",
      "│    │    └─1.weight                     ├─64\n",
      "│    │    └─1.bias                       └─64\n",
      "│    │    └─Conv3d: 3-31                 36,928\n",
      "│    │    │    └─weight                  ├─36,864\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─BatchNorm3d: 3-32            128\n",
      "│    │    │    └─weight                  ├─64\n",
      "│    │    │    └─bias                    └─64\n",
      "│    │    └─ReLU: 3-33                   --\n",
      "├─ConvTranspose3d: 1-18                  36,928\n",
      "│    └─weight                            ├─36,864\n",
      "│    └─bias                              └─64\n",
      "├─ConvBlock_1: 1-19                      --\n",
      "│    └─conv_block_1.0.weight             ├─2,304\n",
      "│    └─conv_block_1.0.bias               ├─1\n",
      "│    └─conv_block_1.1.weight             ├─1\n",
      "│    └─conv_block_1.1.bias               └─1\n",
      "│    └─Sequential: 2-13                  --\n",
      "│    │    └─0.weight                     ├─2,304\n",
      "│    │    └─0.bias                       ├─1\n",
      "│    │    └─1.weight                     ├─1\n",
      "│    │    └─1.bias                       └─1\n",
      "│    │    └─Conv3d: 3-34                 2,305\n",
      "│    │    │    └─weight                  ├─2,304\n",
      "│    │    │    └─bias                    └─1\n",
      "│    │    └─BatchNorm3d: 3-35            2\n",
      "│    │    │    └─weight                  ├─1\n",
      "│    │    │    └─bias                    └─1\n",
      "│    │    └─ReLU: 3-36                   --\n",
      "├─ConvBlock_1: 1-20                      --\n",
      "│    └─conv_block_1.0.weight             ├─576\n",
      "│    └─conv_block_1.0.bias               ├─32\n",
      "│    └─conv_block_1.1.weight             ├─32\n",
      "│    └─conv_block_1.1.bias               └─32\n",
      "│    └─Sequential: 2-14                  --\n",
      "│    │    └─0.weight                     ├─576\n",
      "│    │    └─0.bias                       ├─32\n",
      "│    │    └─1.weight                     ├─32\n",
      "│    │    └─1.bias                       └─32\n",
      "│    │    └─Conv3d: 3-37                 608\n",
      "│    │    │    └─weight                  ├─576\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─BatchNorm3d: 3-38            64\n",
      "│    │    │    └─weight                  ├─32\n",
      "│    │    │    └─bias                    └─32\n",
      "│    │    └─ReLU: 3-39                   --\n",
      "├─Conv3d: 1-21                           577\n",
      "│    └─weight                            ├─576\n",
      "│    └─bias                              └─1\n",
      "=================================================================\n",
      "Total params: 4,025,892\n",
      "Trainable params: 4,025,892\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss = 4601.211859249896, test_loss = 72.66644968778803\n",
      "Epoch 1: train_loss = 1386.0940695206764, test_loss = 93.16012304399665\n",
      "Epoch 2: train_loss = 962.8259085852084, test_loss = 90.67641107516661\n",
      "Epoch 3: train_loss = 778.9067464654213, test_loss = 81.92126317714892\n",
      "Epoch 4: train_loss = 618.6314570583557, test_loss = 79.02913372665427\n",
      "Epoch 5: train_loss = 373.9968543041736, test_loss = 68.26327978070972\n",
      "Epoch 6: train_loss = 337.7397160564445, test_loss = 69.28314471635561\n",
      "Epoch 7: train_loss = 242.41798426958886, test_loss = 87.6059146700112\n",
      "Epoch 8: train_loss = 218.2933764023284, test_loss = 93.77702935452159\n",
      "Epoch 9: train_loss = 189.5418383287694, test_loss = 83.64633615784504\n",
      "Epoch 10: train_loss = 186.7633554768878, test_loss = 72.20826710850358\n",
      "Epoch 11: train_loss = 159.34030437061867, test_loss = 71.03175517705662\n",
      "Epoch 12: train_loss = 127.37370488061106, test_loss = 72.83349367944902\n",
      "Epoch 13: train_loss = 113.72762379358738, test_loss = 78.92608907241643\n",
      "Epoch 14: train_loss = 106.39537262244092, test_loss = 70.74964828959946\n",
      "Epoch 15: train_loss = 105.322831181441, test_loss = 68.8153617689313\n",
      "Epoch 16: train_loss = 101.48470908176118, test_loss = 69.12712036606759\n",
      "Epoch 17: train_loss = 93.95014393792714, test_loss = 70.35363186703749\n",
      "Epoch 18: train_loss = 88.05723532470311, test_loss = 73.04307010636828\n",
      "Epoch 19: train_loss = 85.43367554276453, test_loss = 70.93457673305025\n",
      "Epoch 20: train_loss = 85.70214498777928, test_loss = 70.071429068533\n",
      "Epoch 21: train_loss = 83.36605599178542, test_loss = 69.8729533072331\n",
      "Epoch 22: train_loss = 80.42608837193107, test_loss = 70.12111984104914\n",
      "Epoch 23: train_loss = 81.53111465181247, test_loss = 70.62701222185437\n",
      "Epoch 24: train_loss = 80.85481533500422, test_loss = 72.45276995776734\n",
      "Epoch 25: train_loss = 82.46274895583655, test_loss = 71.51530939993114\n",
      "Epoch 26: train_loss = 81.51333891938027, test_loss = 74.45251396472233\n",
      "Epoch 27: train_loss = 80.6281392363109, test_loss = 71.43484250673744\n",
      "Epoch 28: train_loss = 80.1271151533253, test_loss = 71.68118485419902\n",
      "Epoch 29: train_loss = 78.76116779507551, test_loss = 72.74051879142776\n",
      "Epoch 30: train_loss = 78.51900084121566, test_loss = 73.50220021228596\n",
      "Epoch 31: train_loss = 78.47579323312321, test_loss = 73.52407044434428\n",
      "Epoch 32: train_loss = 78.21339344099279, test_loss = 74.14072408784006\n",
      "Epoch 33: train_loss = 78.49927280435372, test_loss = 73.11865992636456\n",
      "Epoch 34: train_loss = 78.37718850772006, test_loss = 75.26209891793354\n",
      "Epoch 35: train_loss = 78.06644693562846, test_loss = 73.43926712292541\n",
      "Epoch 36: train_loss = 78.75130197814066, test_loss = 82.36083368388535\n",
      "Epoch 37: train_loss = 78.5502600442668, test_loss = 76.69962445000863\n",
      "Epoch 38: train_loss = 78.19794928054041, test_loss = 91.36221441999399\n",
      "Epoch 39: train_loss = 81.61516346500501, test_loss = 75.53950375063874\n",
      "Epoch 40: train_loss = 79.02539419256625, test_loss = 83.72074046443623\n",
      "Epoch 41: train_loss = 77.98921841974128, test_loss = 75.63066065338467\n",
      "Epoch 42: train_loss = 77.4924054198734, test_loss = 82.33810735864787\n",
      "Epoch 43: train_loss = 76.93964574985408, test_loss = 76.89974491827171\n",
      "Epoch 44: train_loss = 79.71269822817864, test_loss = 84.15397842762755\n",
      "Epoch 45: train_loss = 77.81857644087025, test_loss = 73.04368351338884\n",
      "Epoch 46: train_loss = 76.0498070309108, test_loss = 81.01543039735176\n",
      "Epoch 47: train_loss = 76.76514327168836, test_loss = 77.17131079377302\n",
      "Epoch 48: train_loss = 77.42565579579482, test_loss = 93.18762565063749\n",
      "Epoch 49: train_loss = 81.04386071943183, test_loss = 76.26658205749376\n",
      "Epoch 50: train_loss = 78.24982934279261, test_loss = 84.73425205066562\n",
      "Epoch 51: train_loss = 76.38739675011925, test_loss = 77.33291140404204\n",
      "Epoch 52: train_loss = 76.66489321346859, test_loss = 85.61269920467751\n",
      "Epoch 53: train_loss = 79.27961849472344, test_loss = 72.1756963769043\n",
      "Epoch 54: train_loss = 78.59696930246851, test_loss = 71.9111507213742\n",
      "Epoch 55: train_loss = 75.87184072932764, test_loss = 72.58240175077809\n",
      "Epoch 56: train_loss = 76.30676485239641, test_loss = 72.38719791324574\n",
      "Epoch 57: train_loss = 75.92182028452342, test_loss = 73.54553318465646\n",
      "Epoch 58: train_loss = 75.34133088430421, test_loss = 71.80185473477917\n",
      "Epoch 59: train_loss = 75.73782090972794, test_loss = 75.59731069980666\n",
      "Epoch 60: train_loss = 77.3192000019063, test_loss = 74.98921666491879\n",
      "Epoch 61: train_loss = 77.24770874824218, test_loss = 76.40432750240909\n",
      "Epoch 62: train_loss = 76.34110208576517, test_loss = 71.81390516581405\n",
      "Epoch 63: train_loss = 76.66657553119904, test_loss = 71.87976754780253\n",
      "Epoch 64: train_loss = 76.67493936889925, test_loss = 84.31814957456285\n",
      "Epoch 65: train_loss = 78.08177189779173, test_loss = 72.77772398259647\n",
      "Epoch 66: train_loss = 76.04320206065249, test_loss = 72.69920001054265\n",
      "Epoch 67: train_loss = 75.5579659548009, test_loss = 72.45885377055488\n",
      "Epoch 68: train_loss = 76.7508047002255, test_loss = 72.61766322435824\n",
      "Epoch 69: train_loss = 76.73476616557197, test_loss = 87.51193262460296\n",
      "Epoch 70: train_loss = 78.53948029977859, test_loss = 73.68338075617785\n",
      "Epoch 71: train_loss = 76.15548468888463, test_loss = 82.59000195485592\n",
      "Epoch 72: train_loss = 77.71750776958021, test_loss = 70.89144052061775\n",
      "Epoch 73: train_loss = 77.29612954711034, test_loss = 70.77537118637358\n",
      "Epoch 74: train_loss = 76.32683468793005, test_loss = 76.6174805430386\n",
      "Epoch 75: train_loss = 74.50513961372383, test_loss = 70.82094961120671\n",
      "Epoch 76: train_loss = 74.28321398863564, test_loss = 76.16184084419271\n",
      "Epoch 77: train_loss = 75.24629329559316, test_loss = 70.91713712512954\n",
      "Epoch 78: train_loss = 73.70166985993262, test_loss = 75.78881490312448\n",
      "Epoch 79: train_loss = 74.0540687965342, test_loss = 70.63855496263173\n",
      "Epoch 80: train_loss = 74.13355828031244, test_loss = 73.17694146951023\n",
      "Epoch 81: train_loss = 74.47002708212626, test_loss = 71.34303080704314\n",
      "Epoch 82: train_loss = 75.2543571539917, test_loss = 71.18052889300924\n",
      "Epoch 83: train_loss = 75.44543339910251, test_loss = 78.22284067507849\n",
      "Epoch 84: train_loss = 74.54877454272965, test_loss = 74.71961919664987\n",
      "Epoch 85: train_loss = 74.45448509798673, test_loss = 88.02643770908801\n",
      "Epoch 86: train_loss = 77.41532366831086, test_loss = 72.41395688139627\n",
      "Epoch 87: train_loss = 73.51612677930346, test_loss = 78.33171107457696\n",
      "Epoch 88: train_loss = 73.55140216197218, test_loss = 74.51609352149477\n",
      "Epoch 89: train_loss = 75.85141510900733, test_loss = 73.96092907847999\n",
      "Epoch 90: train_loss = 75.00227133424136, test_loss = 70.9831053726235\n",
      "Epoch 91: train_loss = 73.35145877131656, test_loss = 71.27725126437267\n",
      "Epoch 92: train_loss = 73.48377016671218, test_loss = 72.44780544556957\n",
      "Epoch 93: train_loss = 73.26102209806129, test_loss = 71.10492540640864\n",
      "Epoch 94: train_loss = 72.95456435132527, test_loss = 71.20712864635422\n",
      "Epoch 95: train_loss = 73.22055318874943, test_loss = 70.51511895195898\n",
      "Epoch 96: train_loss = 73.37520398902016, test_loss = 71.05718365047174\n",
      "Epoch 97: train_loss = 73.13112517084208, test_loss = 71.90335511866468\n",
      "Epoch 98: train_loss = 72.84514441787076, test_loss = 70.38655682653462\n",
      "Epoch 99: train_loss = 73.2065884525003, test_loss = 72.36725287223834\n",
      "Epoch 100: train_loss = 72.95952522019486, test_loss = 70.67504874347004\n",
      "Epoch 101: train_loss = 72.55866349074756, test_loss = 71.75802634618842\n",
      "Epoch 102: train_loss = 72.1401256749157, test_loss = 70.31354070347871\n",
      "Epoch 103: train_loss = 73.04958220604865, test_loss = 70.6953468496213\n",
      "Epoch 104: train_loss = 72.81770975557096, test_loss = 72.22501234356625\n",
      "Epoch 105: train_loss = 73.84718370176579, test_loss = 72.10363989044151\n",
      "Epoch 106: train_loss = 75.08801173997912, test_loss = 84.18420373845228\n",
      "Epoch 107: train_loss = 75.43276079056105, test_loss = 72.14154828511664\n",
      "Epoch 108: train_loss = 74.73482116511984, test_loss = 71.96427897343582\n",
      "Epoch 109: train_loss = 74.31415475088271, test_loss = 73.45878700750959\n",
      "Epoch 110: train_loss = 73.13931660674348, test_loss = 70.10123501083184\n",
      "Epoch 111: train_loss = 73.49793114515974, test_loss = 75.26065179424103\n",
      "Epoch 112: train_loss = 72.73315893466507, test_loss = 73.00382859524849\n",
      "Epoch 113: train_loss = 73.78423607046251, test_loss = 75.01455405003377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114: train_loss = 73.00731481858381, test_loss = 70.01831957095928\n",
      "Epoch 115: train_loss = 71.52129278736425, test_loss = 73.29810391539124\n",
      "Epoch 116: train_loss = 71.73301758163272, test_loss = 70.04623595587688\n",
      "Epoch 117: train_loss = 71.91537548940539, test_loss = 72.11799239287576\n",
      "Epoch 118: train_loss = 71.48833690307379, test_loss = 70.01009016330957\n",
      "Epoch 119: train_loss = 71.43650780620956, test_loss = 74.2024948274646\n",
      "Epoch 120: train_loss = 71.53236787827929, test_loss = 70.137587682806\n",
      "Epoch 121: train_loss = 72.02181561129849, test_loss = 73.54469128650274\n",
      "Epoch 122: train_loss = 71.41617465713348, test_loss = 70.07199377355789\n",
      "Epoch 123: train_loss = 71.65643234767543, test_loss = 70.04898469663891\n",
      "Epoch 124: train_loss = 71.23939013181885, test_loss = 70.08805512874392\n",
      "Epoch 125: train_loss = 71.20829248302518, test_loss = 72.50763959727843\n",
      "Epoch 126: train_loss = 71.2019774724093, test_loss = 70.08301450602411\n",
      "Epoch 127: train_loss = 71.37196015885924, test_loss = 72.55509776281949\n",
      "Epoch 128: train_loss = 72.23459115205439, test_loss = 71.7037782111903\n",
      "Epoch 129: train_loss = 72.33910661313223, test_loss = 82.29865252072273\n",
      "Epoch 130: train_loss = 73.86825442609818, test_loss = 77.88473502668951\n",
      "Epoch 131: train_loss = 74.96501940429233, test_loss = 91.64207457193498\n",
      "Epoch 132: train_loss = 75.87941702862307, test_loss = 72.06410908775095\n",
      "Epoch 133: train_loss = 71.69962276715667, test_loss = 77.06368831303837\n",
      "Epoch 134: train_loss = 71.25700359806281, test_loss = 71.18166459221862\n",
      "Epoch 135: train_loss = 72.64420699862762, test_loss = 75.15939033717862\n",
      "Epoch 136: train_loss = 72.47861482324468, test_loss = 69.99271878913953\n",
      "Epoch 137: train_loss = 70.97950461373874, test_loss = 70.18509445281732\n",
      "Epoch 138: train_loss = 70.46762571158347, test_loss = 69.47536452614355\n",
      "Epoch 139: train_loss = 71.51594579803236, test_loss = 69.36519325994351\n",
      "Epoch 140: train_loss = 71.41538911833321, test_loss = 75.4262187448656\n",
      "Epoch 141: train_loss = 72.85873268327514, test_loss = 74.1381113776261\n",
      "Epoch 142: train_loss = 73.89432599722589, test_loss = 84.39926402331466\n",
      "Epoch 143: train_loss = 73.70872724893665, test_loss = 70.50104620769687\n",
      "Epoch 144: train_loss = 70.32292705603321, test_loss = 76.35046809315428\n",
      "Epoch 145: train_loss = 71.1140016537944, test_loss = 69.39069410383826\n",
      "Epoch 146: train_loss = 70.67226006688234, test_loss = 71.26739007985465\n",
      "Epoch 147: train_loss = 70.63319208141924, test_loss = 70.35015389687864\n",
      "Epoch 148: train_loss = 70.09585325939456, test_loss = 70.5697769819008\n",
      "Epoch 149: train_loss = 70.0676634994048, test_loss = 71.25167284444436\n",
      "Epoch 150: train_loss = 70.055703818643, test_loss = 69.68235929934704\n",
      "Epoch 151: train_loss = 69.88186358402473, test_loss = 69.66459208359863\n",
      "Epoch 152: train_loss = 69.82581846117081, test_loss = 71.79150448015665\n",
      "Epoch 153: train_loss = 70.19688651241587, test_loss = 69.90696436487293\n",
      "Epoch 154: train_loss = 70.3416792431482, test_loss = 69.39428744638829\n",
      "Epoch 155: train_loss = 70.66309858525157, test_loss = 74.34924287692601\n",
      "Epoch 156: train_loss = 69.8464532713353, test_loss = 69.58499002601107\n",
      "Epoch 157: train_loss = 70.02688560813958, test_loss = 69.94016321544817\n",
      "Epoch 158: train_loss = 69.99159448866114, test_loss = 73.08767695585429\n",
      "Epoch 159: train_loss = 70.86553302387301, test_loss = 71.28213135662017\n",
      "Epoch 160: train_loss = 70.98484481859433, test_loss = 73.55043084823224\n",
      "Epoch 161: train_loss = 70.4062388760472, test_loss = 69.5199686706718\n",
      "Epoch 162: train_loss = 69.74636252141873, test_loss = 71.0080728079495\n",
      "Epoch 163: train_loss = 70.52071002600938, test_loss = 70.85353680283973\n",
      "Epoch 164: train_loss = 70.21969768197631, test_loss = 69.61240798583636\n",
      "Epoch 165: train_loss = 69.66549668969361, test_loss = 70.63234718911328\n",
      "Epoch 166: train_loss = 69.37004077791113, test_loss = 69.71656170969555\n",
      "Epoch 167: train_loss = 69.14173175983935, test_loss = 69.59951758273647\n",
      "Epoch 168: train_loss = 69.34081890416293, test_loss = 70.93643952185502\n",
      "Epoch 169: train_loss = 69.41816668587255, test_loss = 70.84780298242423\n",
      "Epoch 170: train_loss = 69.1371362580886, test_loss = 70.49636110507487\n",
      "Epoch 171: train_loss = 69.45034095781436, test_loss = 69.5921567953097\n",
      "Epoch 172: train_loss = 69.94441752660829, test_loss = 74.77910206792274\n",
      "Epoch 173: train_loss = 70.0886752579397, test_loss = 69.27514199915981\n",
      "Epoch 174: train_loss = 70.0930275529732, test_loss = 69.13510376298544\n",
      "Epoch 175: train_loss = 69.11095400699794, test_loss = 70.43378851249172\n",
      "Epoch 176: train_loss = 68.72991166691794, test_loss = 69.94355474082084\n",
      "Epoch 177: train_loss = 68.58997549795559, test_loss = 68.94189072740711\n",
      "Epoch 178: train_loss = 69.03187796480039, test_loss = 71.81306144270769\n",
      "Epoch 179: train_loss = 68.73145513022972, test_loss = 69.47382272834403\n",
      "Epoch 180: train_loss = 68.82772331707199, test_loss = 69.07464938691949\n",
      "Epoch 181: train_loss = 68.81530421530711, test_loss = 74.25039146866308\n",
      "Epoch 182: train_loss = 68.87504187392251, test_loss = 69.17364191089999\n",
      "Epoch 183: train_loss = 69.16441389197719, test_loss = 74.92019119907346\n",
      "Epoch 184: train_loss = 68.84121806882948, test_loss = 71.67648775215424\n",
      "Epoch 185: train_loss = 69.98008189596176, test_loss = 73.24602880281563\n",
      "Epoch 186: train_loss = 69.34767042787199, test_loss = 69.42366045972292\n",
      "Epoch 187: train_loss = 69.70609013966924, test_loss = 69.27081199970854\n",
      "Epoch 188: train_loss = 69.67083141905648, test_loss = 76.70389109747384\n",
      "Epoch 189: train_loss = 69.43064021645046, test_loss = 69.32471725792863\n",
      "Epoch 190: train_loss = 68.71476554175798, test_loss = 69.87324029314439\n",
      "Epoch 191: train_loss = 68.38710220581684, test_loss = 71.37499373178338\n",
      "Epoch 192: train_loss = 67.94983323079795, test_loss = 69.38025700499269\n",
      "Epoch 193: train_loss = 68.05213057267501, test_loss = 71.78189112737887\n",
      "Epoch 194: train_loss = 68.17790151225371, test_loss = 69.4627552353945\n",
      "Epoch 195: train_loss = 67.76691602282737, test_loss = 70.4077644086742\n",
      "Epoch 196: train_loss = 67.82160341494382, test_loss = 69.6444182537551\n",
      "Epoch 197: train_loss = 67.65275326729942, test_loss = 70.14353818781188\n",
      "Epoch 198: train_loss = 67.47914078655843, test_loss = 69.09115107205483\n",
      "Epoch 199: train_loss = 67.71422937099511, test_loss = 72.53032925980153\n"
     ]
    }
   ],
   "source": [
    "model = TracNet(n_channels=1)\n",
    "print(summary(model, verbose=2))\n",
    "\n",
    "model.apply(initialize_weight)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0000006, momentum=0.9)\n",
    "#scheduler = StepLR(optimizer, step_size=10, gamma=0.7943)\n",
    "\n",
    "fit(model, optimizer, dataloaders, num_epochs=200)\n",
    "\n",
    "torch.save(model.state_dict(), '/home/alexrichard/LRZ Sync+Share/ML in Physics/toy_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd7feddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TracNet(\n",
       "  (s1): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s2): ConvBlock_2(\n",
       "    (conv_block_2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (s4): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s5): ConvBlock_2(\n",
       "    (conv_block_2): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s6): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (s7): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(128, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s8): ConvBlock_2(\n",
       "    (conv_block_2): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s9): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (s10): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(256, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s11): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s12): ConvTranspose3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "  (s13): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(512, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s14): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s15): ConvTranspose3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "  (s16): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(256, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s17): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s18): ConvTranspose3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "  (s19): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(128, 1, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s20): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s21): Conv3d(32, 1, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TracNet(n_channels=1).double()\n",
    "model.load_state_dict(torch.load('/home/alexrichard/LRZ Sync+Share/ML in Physics/toy_model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06cdb734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test data for working on Martinsried machine\n",
    "test_sample = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dspl/MLData001-00.mat')['dspl'])\n",
    "test_target = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_trac/MLData001-00.mat')['trac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "656e687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_sample[np.newaxis, :][np.newaxis, :]\n",
    "test_target = test_target[np.newaxis, :][np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a592df0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (list), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoveaxis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(test_sample, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmoveaxis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py:1465\u001b[0m, in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dest, src \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(destination, source)):\n\u001b[1;32m   1463\u001b[0m     order\u001b[38;5;241m.\u001b[39minsert(dest, src)\n\u001b[0;32m-> 1465\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (list), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "test_sample = np.moveaxis(test_sample, [1, 2], [2, 3])\n",
    "test_target = np.moveaxis(test_sample, [1, 2], [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cba354fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = torch.from_numpy(test_sample).double().to(device)\n",
    "test_target = torch.from_numpy(test_target).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6796077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    with torch.no_grad():\n",
    "        return model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b193f7e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 5D input (got 4D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [83]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(features):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mTracNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 31\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms2(x1)\n\u001b[1;32m     33\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms3(x2)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mConvBlock_1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:513\u001b[0m, in \u001b[0;36mBatchNorm3d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 5D input (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n",
      "\u001b[0;31mValueError\u001b[0m: expected 5D input (got 4D input)"
     ]
    }
   ],
   "source": [
    "prediction = predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a1b231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_prediction = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/prediction.mat')['ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94f41cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/trac/MLData001-00.mat')['trac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acb92248",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = torch.from_numpy(ground_truth).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9707dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictions, target):\n",
    "    loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "    loss = 0.5 * loss_fn(predictions, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8301b14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(ground_truth, trac_field)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
