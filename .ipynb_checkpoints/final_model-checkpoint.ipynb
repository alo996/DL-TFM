{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73abdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8ccfb",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5decf",
   "metadata": {},
   "source": [
    "Set seeds for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35207a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd2871",
   "metadata": {},
   "source": [
    "Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daba7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b76375",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6d370",
   "metadata": {},
   "source": [
    "Set paths to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ead603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/dspl'\n",
    "dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/dsplRadial'\n",
    "trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/trac'\n",
    "tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50e0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67fe34",
   "metadata": {},
   "source": [
    "Create numpy arrays for samples and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a7f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, dspl_radials, targets, trac_radials = data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path)\n",
    "samples, targets = np.append(samples, dspl_radials), np.append(targets, trac_radials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501441d",
   "metadata": {},
   "source": [
    "Split training data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec1ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(samples, targets, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f15a0d",
   "metadata": {},
   "source": [
    "Extract displacement and traction fields from the training data and reshape to (samples, channels, depth, heigth, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f68b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = np.array([sample['dspl'] for sample in X_train]), np.array([sample['dspl'] for sample in X_val]), np.array([target['trac'] for target in y_train]), np.array([target['trac'] for target in y_val])\n",
    "# Reshape to (samples, channels, depth, height, width)\n",
    "X_train = np.moveaxis(X_train[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "X_val = np.moveaxis(X_val[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y_train = np.moveaxis(y_train[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y_val = np.moveaxis(y_val[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add172fc",
   "metadata": {},
   "source": [
    "Normalize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233af2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_min = X.min(axis=(3, 4), keepdims=True)\n",
    "#x_max = X.max(axis=(3, 4), keepdims=True)\n",
    "#X = (X - x_min)/(x_max-x_min)\n",
    "\n",
    "#y_min = y.min(axis=(3, 4), keepdims=True)\n",
    "#y_max = y.max(axis=(3, 4), keepdims=True)\n",
    "#y = (y - y_min)/(y_max-y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347a2ed",
   "metadata": {},
   "source": [
    "Convert train and validation data to Pytorch tensors and load them to respective device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57aa8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).double().to(device)\n",
    "X_val = torch.from_numpy(X_val).double().to(device)\n",
    "y_train = torch.from_numpy(y_train).double().to(device)\n",
    "y_val = torch.from_numpy(y_val).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac94f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=False)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=2*batch_size, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b6657",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c680b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 17:33:25.659117: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-20 17:33:25.659135: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "NAME = \"TracNet104-{:%Y-%b-%d %H:%M:%S}\".format(datetime.datetime.now())\n",
    "writer = SummaryWriter(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e59ae588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_1(nn.Module):\n",
    "    \"\"\"Conv3D -> BatchNorm -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0159c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_2(nn.Module):\n",
    "    \"\"\"Conv3D -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1865b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.s1 = ConvBlock_1(n_channels, 32)\n",
    "        self.s2 = ConvBlock_2(32, 64)\n",
    "        self.s3 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s4 = ConvBlock_1(64, 64)\n",
    "        self.s5 = ConvBlock_2(64, 128)\n",
    "        self.s6 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s7 = ConvBlock_1(128, 128)\n",
    "        self.s8 = ConvBlock_2(128, 256)\n",
    "        self.s9 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s10 = ConvBlock_1(256, 128)\n",
    "        self.s11 = ConvBlock_1(128, 256)\n",
    "        self.s12 = nn.ConvTranspose3d(256, 256, kernel_size=(1, 3, 3), stride=(1,2,2))\n",
    "        #fusion3\n",
    "        self.s13 = ConvBlock_1(512, 64)\n",
    "        self.s14 = ConvBlock_1(64, 128)\n",
    "        self.s15 = nn.ConvTranspose3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion2\n",
    "        self.s16 = ConvBlock_1(256, 32)\n",
    "        self.s17 = ConvBlock_1(32, 64)\n",
    "        self.s18 = nn.ConvTranspose3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion1\n",
    "        self.s19 = ConvBlock_1(128, 1)\n",
    "        self.s20 = ConvBlock_1(1, 32)\n",
    "        self.s21 = nn.Conv3d(32, 1, kernel_size=(2, 3, 3), padding='same')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.s1(x)\n",
    "        x2 = self.s2(x1)\n",
    "        x3 = self.s3(x2)\n",
    "        x4 = self.s4(x3)\n",
    "        x5 = self.s5(x4)\n",
    "        x6 = self.s6(x5)\n",
    "        x7 = self.s7(x6)\n",
    "        x8 = self.s8(x7)\n",
    "        x9 = self.s9(x8)\n",
    "        x10 = self.s10(x9) \n",
    "        x11 = self.s11(x10)\n",
    "        x12 = self.s12(x11)\n",
    "        padded = torch.nn.functional.pad(x12, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion3 = torch.cat((x8, padded), dim=1)\n",
    "        x13 = self.s13(fusion3)\n",
    "        x14 = self.s14(x13)\n",
    "        x15 = self.s15(x14)\n",
    "        padded = torch.nn.functional.pad(x15, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion2 = torch.cat((x5, padded), dim=1)\n",
    "        x16 = self.s16(fusion2)\n",
    "        x17 = self.s17(x16)\n",
    "        x18 = self.s18(x17)\n",
    "        padded = torch.nn.functional.pad(x18, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion1 = torch.cat((x2, padded), dim=1)\n",
    "        x19 = self.s19(fusion1)\n",
    "        x20 = self.s20(x19)\n",
    "        logits = self.s21(x20)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c1cd2",
   "metadata": {},
   "source": [
    "Sample weights for convolutional layers from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa126d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        torch.nn.init.normal_(module.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77e085",
   "metadata": {},
   "source": [
    "Define custom loss function corresponding to the forward loss function in the Matlab regression layer for image-to-image networks \n",
    " \n",
    "$${loss} = \\frac{1}{2} \\sum \\limits _{p=1} ^{HWC} (t_{p} - y_{p})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453e6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_Loss, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss = 0.5 * torch.sum(torch.pow(target - predictions, 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbd5a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, optimizer, dataloader, train):\n",
    "    model = model.double()\n",
    "    loss_fn = Custom_Loss()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Set model to training mode\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_rmse = 0.0\n",
    "    \n",
    "    # Iterate over data\n",
    "    for xb, yb in dataloader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        \n",
    "        # zero the parameters\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # forward\n",
    "        with torch.set_grad_enabled(train):\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # backward + optimize if in training phase\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2)                \n",
    "                optimizer.step()\n",
    "                \n",
    "        # statistics\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(dataloader.dataset)\n",
    "    epoch_rmse = np.sqrt(2 * epoch_loss)\n",
    "    return epoch_loss, epoch_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3874cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, scheduler, dataloaders, max_epochs, patience):\n",
    "    best_val_rmse = np.inf\n",
    "    best_epoch = -1\n",
    "    \n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        train_loss, train_rmse = run_epoch(model, optimizer, dataloaders['train'], train=True)\n",
    "        scheduler.step()\n",
    "        val_loss, val_rmse = run_epoch(model, None, dataloaders['val'], train=False)\n",
    "        print(f\"Epoch {epoch}/{max_epochs}, train loss: {train_loss:.3f}, train rmse: {train_rmse:.3f}, val loss: {val_loss:.3f}, val rmse: {val_rmse:.3f}\")\n",
    "        \n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_rmse', train_rmse, epoch)\n",
    "        writer.add_scalar('val_loss', val_loss, epoch)\n",
    "        writer.add_scalar('val_rmse', val_rmse, epoch)\n",
    "        \n",
    "        # Save best weights\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_epoch = epoch\n",
    "            best_rmse = val_rmse\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        # Early stopping\n",
    "        print(f\"best epoch: {best_epoch}, best val_rmse: {best_rmse:.3f}, epoch: {epoch}, best_epoch {best_epoch}\")\n",
    "        if epoch - best_epoch >= patience:\n",
    "            break\n",
    "        \n",
    "    torch.save(best_model_weights, f'/home/alexrichard/LRZ Sync+Share/ML in Physics/{NAME}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81a64a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexrichard/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:587: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n",
      "  return F.conv3d(\n"
     ]
    }
   ],
   "source": [
    "model = TracNet(n_channels=1)\n",
    "\n",
    "model.apply(initialize_weight)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0006, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.7943, verbose=True)\n",
    "\n",
    "fit(model, optimizer, scheduler, dataloaders, max_epochs=100, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7feddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'/home/alexrichard/LRZ Sync+Share/ML in Physics/{NAME}.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45e9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(summary(model, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6796077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    with torch.no_grad():\n",
    "        return model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9ad2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
