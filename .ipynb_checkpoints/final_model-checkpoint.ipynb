{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73abdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef13c7",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5decf",
   "metadata": {},
   "source": [
    "Set seeds for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35207a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd2871",
   "metadata": {},
   "source": [
    "Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daba7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6832046",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc550aa",
   "metadata": {},
   "source": [
    "Set paths to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ead603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dspl'\n",
    "foo_dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dsplRadial'\n",
    "foo_trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_trac'\n",
    "foo_tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50e0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028e458",
   "metadata": {},
   "source": [
    "Create numpy arrays for samples and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a7f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, dspl_radials, targets, trac_radials = data_to_npArrays(foo_dspl_path, foo_dsplRadial_path, foo_trac_path, foo_tracRadial_path)\n",
    "samples, targets = np.append(samples, dspl_radials), np.append(targets, trac_radials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cac9bd",
   "metadata": {},
   "source": [
    "Extract displacement and traction fields from the training data and reshape to (samples, channels, depth, heigth, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f68b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array([sample['dspl'] for sample in samples]), np.array([target['trac'] for target in targets])\n",
    "# Reshape to (samples, channels, depth, height, width)\n",
    "X = np.moveaxis(X[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y = np.moveaxis(y[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add172fc",
   "metadata": {},
   "source": [
    "Normalize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea891f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_min = X.min(axis=(3, 4), keepdims=True)\n",
    "#x_max = X.max(axis=(3, 4), keepdims=True)\n",
    "#X = (X - x_min)/(x_max-x_min)\n",
    "\n",
    "#y_min = y.min(axis=(3, 4), keepdims=True)\n",
    "#y_max = y.max(axis=(3, 4), keepdims=True)\n",
    "#y = (y - y_min)/(y_max-y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220660d",
   "metadata": {},
   "source": [
    "Split training data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95cf2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c8ae6",
   "metadata": {},
   "source": [
    "Convert train and validation data to Pytorch tensors and load them to respective device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57aa8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).double().to(device)\n",
    "X_val = torch.from_numpy(X_val).double().to(device)\n",
    "y_train = torch.from_numpy(y_train).double().to(device)\n",
    "y_val = torch.from_numpy(y_val).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac94f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f8731",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9809e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 16:10:28.464546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-19 16:10:28.464569: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/toy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e59ae588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_1(nn.Module):\n",
    "    \"\"\"Conv3D -> BatchNorm -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0159c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock_2(nn.Module):\n",
    "    \"\"\"Conv3D -> ReLU\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(2,3,3), padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1865b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.s1 = ConvBlock_1(n_channels, 32)\n",
    "        self.s2 = ConvBlock_2(32, 64)\n",
    "        self.s3 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s4 = ConvBlock_1(64, 64)\n",
    "        self.s5 = ConvBlock_2(64, 128)\n",
    "        self.s6 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s7 = ConvBlock_1(128, 128)\n",
    "        self.s8 = ConvBlock_2(128, 256)\n",
    "        self.s9 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.s10 = ConvBlock_1(256, 128)\n",
    "        self.s11 = ConvBlock_1(128, 256)\n",
    "        self.s12 = nn.ConvTranspose3d(256, 256, kernel_size=(1, 3, 3), stride=(1,2,2))\n",
    "        #fusion3\n",
    "        self.s13 = ConvBlock_1(512, 64)\n",
    "        self.s14 = ConvBlock_1(64, 128)\n",
    "        self.s15 = nn.ConvTranspose3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion2\n",
    "        self.s16 = ConvBlock_1(256, 32)\n",
    "        self.s17 = ConvBlock_1(32, 64)\n",
    "        self.s18 = nn.ConvTranspose3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
    "        #fusion1\n",
    "        self.s19 = ConvBlock_1(128, 1)\n",
    "        self.s20 = ConvBlock_1(1, 32)\n",
    "        self.s21 = nn.Conv3d(32, 1, kernel_size=(2, 3, 3), padding='same')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.s1(x)\n",
    "        x2 = self.s2(x1)\n",
    "        x3 = self.s3(x2)\n",
    "        x4 = self.s4(x3)\n",
    "        x5 = self.s5(x4)\n",
    "        x6 = self.s6(x5)\n",
    "        x7 = self.s7(x6)\n",
    "        x8 = self.s8(x7)\n",
    "        x9 = self.s9(x8)\n",
    "        x10 = self.s10(x9) \n",
    "        x11 = self.s11(x10)\n",
    "        x12 = self.s12(x11)\n",
    "        padded = torch.nn.functional.pad(x12, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion3 = torch.cat((x8, padded), dim=1)\n",
    "        x13 = self.s13(fusion3)\n",
    "        x14 = self.s14(x13)\n",
    "        x15 = self.s15(x14)\n",
    "        padded = torch.nn.functional.pad(x15, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion2 = torch.cat((x5, padded), dim=1)\n",
    "        x16 = self.s16(fusion2)\n",
    "        x17 = self.s17(x16)\n",
    "        x18 = self.s18(x17)\n",
    "        padded = torch.nn.functional.pad(x18, (0,-1,0,-1), 'constant', 0)\n",
    "        fusion1 = torch.cat((x2, padded), dim=1)\n",
    "        x19 = self.s19(fusion1)\n",
    "        x20 = self.s20(x19)\n",
    "        logits = self.s21(x20)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7251f0",
   "metadata": {},
   "source": [
    "Sample weights for convolutional layers from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa126d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        torch.nn.init.normal_(module.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d32ec2",
   "metadata": {},
   "source": [
    "Define custom loss function corresponding to the forward loss function in the Matlab regression layer for image-to-image networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453e6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_MSE, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "        loss = 0.5 * loss_fn(predictions, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91472aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, optimizer, dataloader, train):\n",
    "    model = model.double()\n",
    "    loss_fn = Custom_MSE()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Set model to training mode\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_rmse = 0.0\n",
    "    \n",
    "    # Iterate over data\n",
    "    for xb, yb in dataloader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        \n",
    "        # zero the parameters\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # forward\n",
    "        with torch.set_grad_enabled(train):\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            rmse = torch.sqrt(2 * loss)\n",
    "            \n",
    "            # backward + optimize if in training phase\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2)                \n",
    "                optimizer.step()\n",
    "                \n",
    "        # statistics\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_rmse += rmse\n",
    "    \n",
    "    epoch_loss /= len(dataloader.dataset)\n",
    "    epoch_rmse /= len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61db835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, scheduler, dataloaders, max_epochs, patience):\n",
    "    best_val_rmse = np.inf\n",
    "    best_epoch = -1\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss, train_rmse = run_epoch(model, optimizer, dataloaders['train'], train=True)\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch + 1: >3}/{max_epochs}, train loss: {train_loss}, train rmse: {train_rmse}\")\n",
    "        \n",
    "        val_loss, val_rmse = run_epoch(model, None, dataloaders['val'], train=False)\n",
    "        print(f\"Epoch {epoch + 1: >3}/{max_epochs}, val loss: {val_loss}, val rmse: {val_rmse}\")\n",
    "        \n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_rmse', train_rmse, epoch)\n",
    "        writer.add_scalar('val_loss', val_loss, epoch)\n",
    "        writer.add_scalar('val_rmse', val_rmse, epoch)\n",
    "        \n",
    "        # Save best weights\n",
    "        if val_rmse <= best_val_rmse:\n",
    "            best_epoch = epoch\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        # Early stopping\n",
    "        if epoch - best_epoch >= patience:\n",
    "            break\n",
    "            \n",
    "    model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df81a64a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexrichard/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:587: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/3, train loss: 264.0619107018127, train rmse: 10.772045310385531\n",
      "Epoch   1/3, val loss: 251.776922381051, val rmse: 10.035475521988005\n",
      "Epoch   2/3, train loss: 215.60445745870666, train rmse: 9.639038006637334\n",
      "Epoch   2/3, val loss: 251.2415877435413, val rmse: 10.02480100038981\n",
      "Epoch   3/3, train loss: 185.51297429492197, train rmse: 9.521329075099349\n",
      "Epoch   3/3, val loss: 251.34427402661055, val rmse: 10.026849435921745\n"
     ]
    }
   ],
   "source": [
    "model = TracNet(n_channels=1)\n",
    "\n",
    "model.apply(initialize_weight)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0006, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.7943)\n",
    "\n",
    "fit(model, optimizer, scheduler, dataloaders, max_epochs=3, patience=5)\n",
    "\n",
    "torch.save(model.state_dict(), '/home/alexrichard/LRZ Sync+Share/ML in Physics/toy_model_weights_adam.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd7feddc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TracNet(\n",
       "  (s1): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s2): ConvBlock_2(\n",
       "    (conv_block_2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (s4): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s5): ConvBlock_2(\n",
       "    (conv_block_2): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s6): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (s7): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(128, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s8): ConvBlock_2(\n",
       "    (conv_block_2): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s9): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (s10): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(256, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s11): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s12): ConvTranspose3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "  (s13): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(512, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s14): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s15): ConvTranspose3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "  (s16): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(256, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s17): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s18): ConvTranspose3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "  (s19): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(128, 1, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s20): ConvBlock_1(\n",
       "    (conv_block_1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s21): Conv3d(32, 1, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TracNet(n_channels=1).double()\n",
    "model.load_state_dict(torch.load('/home/alexrichard/LRZ Sync+Share/ML in Physics/toy_model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06cdb734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test data for working on Martinsried machine\n",
    "test_sample = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_dspl/MLData001-00.mat')['dspl'])\n",
    "test_target = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/foo_trac/MLData001-00.mat')['trac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4576adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = torch.from_numpy(test_sample).double().to(device)\n",
    "test_target = torch.from_numpy(test_target).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6796077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    with torch.no_grad():\n",
    "        return model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc5f425c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/prediction.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/prediction.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matlab_prediction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/prediction.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mans\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    225\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    226\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m/usr/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/prediction.mat'"
     ]
    }
   ],
   "source": [
    "matlab_prediction = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/prediction.mat')['ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f41cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.array(loadmat('/home/alexrichard/LRZ Sync+Share/ML in Physics/DL-TFM-main/train/trainData104/trac/MLData001-00.mat')['trac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = torch.from_numpy(ground_truth).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27292057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictions, target):\n",
    "    loss_fn = nn.MSELoss(reduction = 'sum')\n",
    "    loss = 0.5 * loss_fn(predictions, target)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
