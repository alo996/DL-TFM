{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2774dc7e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7b354df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import shapely as sh\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as math\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Accuracy, RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Conv3DTranspose, BatchNormalization, Activation, \\\n",
    "    Concatenate\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764f8b7",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26bf55",
   "metadata": {},
   "source": [
    "Specify paths to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01828116",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/dspl'\n",
    "dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/dsplRadial'\n",
    "trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/trac'\n",
    "tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/tracRadial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9fa7d",
   "metadata": {},
   "source": [
    "Paths to small subsets of original data for bug fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65332a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_dspl'\n",
    "foo_dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_dsplRadial'\n",
    "foo_trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_trac'\n",
    "foo_tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/data/train/trainData104/foo_tracRadial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676e052",
   "metadata": {},
   "source": [
    "`datasets` saves the training and test data in arrays of dictionaries of the form {'brdx': array, 'brdy': array, 'dspl' or 'trac' = array, 'name': String}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7f86cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets(dspl_path, dsplRadial_path, trac_path, tracRadial_path):\n",
    "    number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples, dtype=double)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials, dtype=double)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets, dtype=double)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials, dtype=double)\n",
    "\n",
    "    return samples, dspl_radials, targets, trac_radials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e24d2",
   "metadata": {},
   "source": [
    "Set seed for reproducability and generate the training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b7826cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "samples, dspl_radials, targets, trac_radials = datasets(foo_dspl_path, foo_dsplRadial_path, foo_trac_path, foo_tracRadial_path)\n",
    "samples, targets = np.append(samples, dspl_radials), np.append(targets, trac_radials)\n",
    "\n",
    "X, y = np.array([sample['dspl'] for sample in samples]), np.array([target['trac'] for target in targets])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = X_train.reshape(((len(X_train), 104, 104, 2, 1))), X_val.reshape(((len(X_val), 104, 104, 2, 1))), y_train.reshape(((len(y_train), 104, 104, 2, 1))), y_val.reshape(((len(y_val), 104, 104, 2, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af2cb1",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ad1b179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters, snd_batch_normalization=True):\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    x = Conv3D(filters=num_filters, kernel_size=(3, 3, 2), padding='same', kernel_initializer=initializer,\n",
    "               bias_initializer='zeros')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv3D(filters=num_filters, kernel_size=(3, 3, 2), padding='same', kernel_initializer=initializer,\n",
    "               bias_initializer='zeros')(x)\n",
    "    if snd_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "70b56733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters, snd_batch_normalization=False)\n",
    "    p = MaxPooling3D(pool_size=(2, 2, 1), strides=(2, 2, 1), padding='same')(x)\n",
    "\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4502635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(input, skip_features, num_filters):\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    x = Conv3DTranspose(filters=num_filters, kernel_size=(3, 3, 1), strides=(2, 2, 1),\n",
    "                        kernel_initializer=initializer, bias_initializer='zeros', padding='same')(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters, snd_batch_normalization=True)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1b59a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tracnet(input_shape, batch_size):\n",
    "    # entry point into graph of layers\n",
    "    inputs = Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # convolution and max-pooling operations with specified numbers of filters\n",
    "    s1, p1 = encoder_block(inputs, 32)\n",
    "    s2, p2 = encoder_block(p1, 64)\n",
    "    s3, p3 = encoder_block(p2, 128)\n",
    "\n",
    "    # base\n",
    "    b1 = conv_block(p3, 256)\n",
    "\n",
    "    # convolution and upsampling operations with specified numbers of filters\n",
    "    d1 = decoder_block(b1, s3, 128)\n",
    "    d2 = decoder_block(d1, s2, 64)\n",
    "    d3 = decoder_block(d2, s1, 32)\n",
    "\n",
    "    # output\n",
    "    initializer = RandomNormal(mean=0.0, stddev=0.01)\n",
    "    outputs = Conv3D(filters=1, kernel_size=(3, 3, 2), padding='same', kernel_initializer=initializer,\n",
    "                     bias_initializer='zeros')(d3)\n",
    "\n",
    "    # build model\n",
    "    model = Model(inputs, outputs, name='Tracnet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658c6b3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "519811e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_mse(y_true, y_pred):\n",
    "    result = 0.5 * math.reduce_sum(math.pow(y_true - y_pred, 2))\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "30f37b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_step_decay(epoch):\n",
    "    initial_lr = 6e-4\n",
    "    drop_rate = 0.7943\n",
    "    epochs_drop = 10.0\n",
    "    \n",
    "    return initial_lr * np.power(drop_rate, np.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8856e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tracnet(X_train, X_val, y_train, y_val, input_shape=(104, 104, 2, 1), epochs=50):\n",
    "    batch_size = 3\n",
    "    # Input layer expects (batch size, length, width, depth, channels)\n",
    "    class haltCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('mse') < 3):\n",
    "                print(\"\\n\\n\\nLoss value below 3 so cancelling training!\\n\\n\\n\")\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "    trainingStopCallback = haltCallback()\n",
    "    \n",
    "    model = build_tracnet(input_shape, batch_size)\n",
    "    model.compile(\n",
    "        optimizer=SGD(momentum=0.9),\n",
    "        loss = half_mse,\n",
    "        metrics=['accuracy', half_mse],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[LearningRateScheduler(lr_step_decay, verbose=2)],\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "    # plot accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig('accuracy_1.png')\n",
    "    plt.close()\n",
    "\n",
    "    # plot loss\n",
    "    plt.plot(history.history['half_mse'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig('loss_1.png')\n",
    "    plt.close()\n",
    "\n",
    "    # save model\n",
    "    model.save(\"'model_1.tf'\",save_format='tf',include_optimizer=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "89dc8c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Tracnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)          [(3, 104, 104, 2, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv3d_391 (Conv3D)            (3, 104, 104, 2, 32  608         ['input_28[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_285 (Batch  (3, 104, 104, 2, 32  128        ['conv3d_391[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_366 (Activation)    (3, 104, 104, 2, 32  0           ['batch_normalization_285[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_392 (Conv3D)            (3, 104, 104, 2, 32  18464       ['activation_366[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_367 (Activation)    (3, 104, 104, 2, 32  0           ['conv3d_392[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_81 (MaxPooling3D  (3, 52, 52, 2, 32)  0           ['activation_367[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3d_393 (Conv3D)            (3, 52, 52, 2, 64)   36928       ['max_pooling3d_81[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_286 (Batch  (3, 52, 52, 2, 64)  256         ['conv3d_393[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_368 (Activation)    (3, 52, 52, 2, 64)   0           ['batch_normalization_286[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_394 (Conv3D)            (3, 52, 52, 2, 64)   73792       ['activation_368[0][0]']         \n",
      "                                                                                                  \n",
      " activation_369 (Activation)    (3, 52, 52, 2, 64)   0           ['conv3d_394[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling3d_82 (MaxPooling3D  (3, 26, 26, 2, 64)  0           ['activation_369[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3d_395 (Conv3D)            (3, 26, 26, 2, 128)  147584      ['max_pooling3d_82[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_287 (Batch  (3, 26, 26, 2, 128)  512        ['conv3d_395[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_370 (Activation)    (3, 26, 26, 2, 128)  0           ['batch_normalization_287[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_396 (Conv3D)            (3, 26, 26, 2, 128)  295040      ['activation_370[0][0]']         \n",
      "                                                                                                  \n",
      " activation_371 (Activation)    (3, 26, 26, 2, 128)  0           ['conv3d_396[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling3d_83 (MaxPooling3D  (3, 13, 13, 2, 128)  0          ['activation_371[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3d_397 (Conv3D)            (3, 13, 13, 2, 256)  590080      ['max_pooling3d_83[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_288 (Batch  (3, 13, 13, 2, 256)  1024       ['conv3d_397[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_372 (Activation)    (3, 13, 13, 2, 256)  0           ['batch_normalization_288[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_398 (Conv3D)            (3, 13, 13, 2, 256)  1179904     ['activation_372[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_289 (Batch  (3, 13, 13, 2, 256)  1024       ['conv3d_398[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_373 (Activation)    (3, 13, 13, 2, 256)  0           ['batch_normalization_289[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_transpose_77 (Conv3DTra  (3, 26, 26, 2, 128)  295040     ['activation_373[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_77 (Concatenate)   (3, 26, 26, 2, 256)  0           ['conv3d_transpose_77[0][0]',    \n",
      "                                                                  'activation_371[0][0]']         \n",
      "                                                                                                  \n",
      " conv3d_399 (Conv3D)            (3, 26, 26, 2, 128)  589952      ['concatenate_77[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_290 (Batch  (3, 26, 26, 2, 128)  512        ['conv3d_399[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_374 (Activation)    (3, 26, 26, 2, 128)  0           ['batch_normalization_290[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_400 (Conv3D)            (3, 26, 26, 2, 128)  295040      ['activation_374[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_291 (Batch  (3, 26, 26, 2, 128)  512        ['conv3d_400[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_375 (Activation)    (3, 26, 26, 2, 128)  0           ['batch_normalization_291[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_transpose_78 (Conv3DTra  (3, 52, 52, 2, 64)  73792       ['activation_375[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenate)   (3, 52, 52, 2, 128)  0           ['conv3d_transpose_78[0][0]',    \n",
      "                                                                  'activation_369[0][0]']         \n",
      "                                                                                                  \n",
      " conv3d_401 (Conv3D)            (3, 52, 52, 2, 64)   147520      ['concatenate_78[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_292 (Batch  (3, 52, 52, 2, 64)  256         ['conv3d_401[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_376 (Activation)    (3, 52, 52, 2, 64)   0           ['batch_normalization_292[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_402 (Conv3D)            (3, 52, 52, 2, 64)   73792       ['activation_376[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_293 (Batch  (3, 52, 52, 2, 64)  256         ['conv3d_402[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_377 (Activation)    (3, 52, 52, 2, 64)   0           ['batch_normalization_293[0][0]']\n",
      "                                                                                                  \n",
      " conv3d_transpose_79 (Conv3DTra  (3, 104, 104, 2, 32  18464      ['activation_377[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_79 (Concatenate)   (3, 104, 104, 2, 64  0           ['conv3d_transpose_79[0][0]',    \n",
      "                                )                                 'activation_367[0][0]']         \n",
      "                                                                                                  \n",
      " conv3d_403 (Conv3D)            (3, 104, 104, 2, 32  36896       ['concatenate_79[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_294 (Batch  (3, 104, 104, 2, 32  128        ['conv3d_403[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_378 (Activation)    (3, 104, 104, 2, 32  0           ['batch_normalization_294[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_404 (Conv3D)            (3, 104, 104, 2, 32  18464       ['activation_378[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_295 (Batch  (3, 104, 104, 2, 32  128        ['conv3d_404[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_379 (Activation)    (3, 104, 104, 2, 32  0           ['batch_normalization_295[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_405 (Conv3D)            (3, 104, 104, 2, 1)  577         ['activation_379[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,896,673\n",
      "Trainable params: 3,894,305\n",
      "Non-trainable params: 2,368\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 1/5\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(1463.6338, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(1463.6338, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(2129304.0, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(2129304.0, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(8.1791955e+17, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(8.1791955e+17, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4/4 - 4s - loss: nan - accuracy: 0.7288 - half_mse: nan - val_loss: nan - val_accuracy: 0.9754 - val_half_mse: nan - lr: 6.0000e-04 - 4s/epoch - 1s/step\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 2/5\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4/4 - 4s - loss: nan - accuracy: 0.9725 - half_mse: nan - val_loss: nan - val_accuracy: 0.9754 - val_half_mse: nan - lr: 6.0000e-04 - 4s/epoch - 1s/step\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 3/5\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4/4 - 4s - loss: nan - accuracy: 0.9725 - half_mse: nan - val_loss: nan - val_accuracy: 0.9754 - val_half_mse: nan - lr: 6.0000e-04 - 4s/epoch - 1s/step\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 4/5\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4/4 - 4s - loss: nan - accuracy: 0.9725 - half_mse: nan - val_loss: nan - val_accuracy: 0.9754 - val_half_mse: nan - lr: 6.0000e-04 - 4s/epoch - 1s/step\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0006.\n",
      "Epoch 5/5\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4/4 - 4s - loss: nan - accuracy: 0.9725 - half_mse: nan - val_loss: nan - val_accuracy: 0.9754 - val_half_mse: nan - lr: 6.0000e-04 - 4s/epoch - 1s/step\n",
      "INFO:tensorflow:Assets written to: 'model_1.tf'/assets\n"
     ]
    }
   ],
   "source": [
    "model = train_tracnet(X_train, X_val, y_train, y_val, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "985421c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape\n",
    "array_sum = np.sum(X_val)\n",
    "array_has_nan = np.isnan(array_sum)\n",
    "array_has_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "afd87b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f7ea393b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 104, 104, 2, 1)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c09bae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = tf.convert_to_tensor(y_val[0])\n",
    "y2 = tf.convert_to_tensor(y_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "96d7f8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=90.29935024720857>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.reduce_sum(math.pow(y1 - y2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4a879771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=90.29935024720857>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.reduce_sum(math.pow(y1 - y2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "45804298",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.5 * math.reduce_sum(math.pow(y1 - y2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f1158ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "e = tf.matmul(c, d)\n",
    "f = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "g = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "h = tf.matmul(f, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3be14eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1., 3.],\n",
       "        [3., 7.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[23., 34.],\n",
       "        [31., 46.]], dtype=float32)>)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d0edd234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3750.0>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.reduce_sum(math.pow(e - h, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475f337",
   "metadata": {},
   "source": [
    "## Error calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a197c33",
   "metadata": {},
   "source": [
    "For a given displacement field, calculate the predicted stress field and the normalized rmse relative to its ground truth for different Young's moduli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fadc0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(path):\n",
    "    errors = []\n",
    "    S = 160\n",
    "    y_moduli = [2500, 5000, 10000, 20000, 400000]\n",
    "    noise = 0.00765\n",
    "    for nr in range(18, 56):\n",
    "        name = f'MLData00{nr}.mat'.format\n",
    "        path = os.path.join(path, name)\n",
    "        if os.path.isfile(path):\n",
    "            cell = [nr]\n",
    "            trac_file = loadmat(path)\n",
    "            brdx = trac_file['brdx']\n",
    "            brdy = trac_file['brdy']\n",
    "            tracGT = trac_file['tracGT']\n",
    "            for i in y_moduli:\n",
    "                name = f'MLData00{nr}-{i}.mat'.format(nr=nr, i=i)\n",
    "                path = os.path.join(path, name)\n",
    "                if os.path.isfile(path):\n",
    "                    dspl_file = loadmat(path)\n",
    "                    dspl = dspl_file['dspl']\n",
    "                    trac = predictTrac(dspl, i)\n",
    "                    err = errorTrac(trac, tracGT, brdx, brdy)\n",
    "                    cell.append(err)\n",
    "\n",
    "                    dspl = addNoise(dspl, noise)\n",
    "                    trac = predictTrac(dspl, i)\n",
    "                    err = errorTrac(trac, tracGT, brdx, brdy)\n",
    "                    cell.append(err)\n",
    "                else:\n",
    "                    continue\n",
    "            errors.append(cell)\n",
    "        else:\n",
    "            continue\n",
    "    df = pd.DataFrame(errors, index=['first', 'second'],\n",
    "                      columns=['File ID', '2,500Pa', '2,500Pa N', '5,000Pa', '5,000Pa N', '10,000Pa', '10,000Pa N',\n",
    "                               '20,000Pa', '20,000Pa N', '40,000Pa', '40,000Pa N'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119573f7",
   "metadata": {},
   "source": [
    "`errorTrac` is called by `calcError` to actually perform the error calculation given a predicted stress field and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f93cdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorTrac(filepath, filepath_GT, plot=False):\n",
    "    file = loadmat(filepath)  # load prediction\n",
    "    file_GT = loadmat(filepath_GT) # load ground truth\n",
    "    brdx = file['brdx']  # x-values of predicted cell border\n",
    "    brdy = file['brdy']  # y-values of predicted cell border\n",
    "    trac = file['trac']\n",
    "    tracGT = file_GT['trac']\n",
    "    zipped = np.array(list(zip(brdx[0], brdy[0])))  # array with (x,y) pairs of cell border coordinates\n",
    "    polygon = sh.geometry.Polygon(zipped)  # create polygon\n",
    "\n",
    "    interior = np.zeros((file['dspl'].shape[0], file['dspl'].shape[1]), dtype=int)  # create all zero matrix\n",
    "    for i in range(len(interior)):  # set all elements in interior matrix to 1 that actually lie within the cell\n",
    "        for j in range(len(interior[i])):\n",
    "            point = Point(i, j)\n",
    "            if polygon.contains(point):\n",
    "                interior[i][j] = 1\n",
    "\n",
    "    # plot polygons using geopandas\n",
    "    if plot:\n",
    "        p = gpd.GeoSeries(polygon)\n",
    "        p.plot()\n",
    "        plt.show()\n",
    "\n",
    "    # update prediction and ground truth by discarding areas outside of cell borders\n",
    "    trac[:, :, 1] = trac[:, :, 1] * interior\n",
    "    trac[:, :, 2] = trac[:, :, 2] * interior\n",
    "    tracGT[:, :, 1] = tracGT[:, :, 1] * interior\n",
    "    tracGT[:, :, 2] = tracGT[:, :, 2] * interior\n",
    "\n",
    "    # compute rmse\n",
    "    mse = np.sum(np.pow((trac[:, :, 1] - tracGT[:, :, 1], 2)), np.pow((trac[:, :, 2] - tracGT[:, :, 2], 2)))\n",
    "    rmse = np.sqrt(mse)\n",
    "    msm = np.sum(np.pow(tracGT[:, :, 1], 2) + np.pow(tracGT[:, :, 2], 2))\n",
    "    rmsm = np.sqrt(msm)\n",
    "    error = rmse / rmsm\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789be81",
   "metadata": {},
   "source": [
    "`add_noise` applies Gaussian noise to a displacement field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c394fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(dspl, N):\n",
    "    dsplN = np.zeros(shape=dspl.shape)\n",
    "    S = dspl.shape[0]\n",
    "    stdev = N / np.sqrt(2)\n",
    "    noise = np.random.normal(loc=0, scale=stdev, size=(S, S))\n",
    "    dsplN[:, :, 1] = dspl[:, :, 1] + noise\n",
    "    noise = np.random.normal(loc=0, scale=stdev, size=(S, S))\n",
    "    dsplN[:, :, 2] = dspl[:, :, 2] + noise\n",
    "    \n",
    "    return dsplN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e35c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
