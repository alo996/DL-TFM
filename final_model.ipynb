{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df3eb3e",
   "metadata": {},
   "source": [
    "# DL-TFM in Pytorch I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f7f65",
   "metadata": {},
   "source": [
    "## Imports and technical prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96ec075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracNet import TracNet\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Tuple\n",
    "from scipy.io import loadmat, savemat\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5decf",
   "metadata": {},
   "source": [
    "Set seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a35207a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd2871",
   "metadata": {},
   "source": [
    "Use CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "daba7031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b76375",
   "metadata": {},
   "source": [
    "## 1. Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6d370",
   "metadata": {},
   "source": [
    "Set paths to training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ead603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/dspl'\n",
    "dsplRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/dsplRadial'\n",
    "trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/trac'\n",
    "tracRadial_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/train/trainData104/tracRadial'\n",
    "\n",
    "# Test data\n",
    "test_dspl_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/test/generic/testData104/mini_dspl'\n",
    "test_trac_path = '/home/alexrichard/LRZ Sync+Share/ML in Physics/Repos/DL-TFM-main/test/generic/testData104/mini_trac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e50e0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_npArrays(dspl_path, dsplRadial_path, trac_path, tracRadial_path, test_dspl_path, test_trac_path):\n",
    "    # number_samples = len([name for name in os.listdir(dspl_path) if os.path.isfile(os.path.join(dspl_path, name))])\n",
    "    # number_radials = len([name for name in os.listdir(dsplRadial_path) if os.path.isfile(os.path.join(dsplRadial_path, name))])\n",
    "    \n",
    "    # save all samples in matrix\n",
    "    samples = [] \n",
    "    for i, filename in enumerate(os.listdir(dspl_path)):\n",
    "        f = os.path.join(dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            sample = loadmat(f)\n",
    "            if '__header__' in sample: del sample['__header__']\n",
    "            if '__version__' in sample: del sample['__version__']\n",
    "            if '__globals__' in sample: del sample['__globals__']\n",
    "            sample['name'] = filename\n",
    "            samples = np.append(samples, sample)\n",
    "        else:\n",
    "            continue\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    # save all radial patterns of displacements in matrix\n",
    "    dspl_radials = []\n",
    "    for i, filename in enumerate(os.listdir(dsplRadial_path)):\n",
    "        f = os.path.join(dsplRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            dspl_radials = np.append(dspl_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    dspl_radials = np.array(dspl_radials)\n",
    "    \n",
    "    # save all targets in matrix\n",
    "    targets = []\n",
    "    for i, filename in enumerate(os.listdir(trac_path)):\n",
    "        f = os.path.join(trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target = loadmat(f)\n",
    "            if '__header__' in target: del target['__header__']\n",
    "            if '__version__' in target: del target['__version__']\n",
    "            if '__globals__' in target: del target['__globals__']\n",
    "            target['name'] = filename\n",
    "            targets = np.append(targets, target)\n",
    "        else:\n",
    "            continue \n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # save all radial patterns of traction forces in matrix\n",
    "    trac_radials = []\n",
    "    for i, filename in enumerate(os.listdir(tracRadial_path)):\n",
    "        f = os.path.join(tracRadial_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            radial = loadmat(f)\n",
    "            if '__header__' in radial: del radial['__header__']\n",
    "            if '__version__' in radial: del radial['__version__']\n",
    "            if '__globals__' in radial: del radial['__globals__']\n",
    "            radial['name'] = filename\n",
    "            trac_radials = np.append(trac_radials, radial)\n",
    "        else:\n",
    "            continue\n",
    "    trac_radials = np.array(trac_radials)\n",
    "    \n",
    "    # save test displacements in matrix\n",
    "    test_dspls = [] \n",
    "    for i, filename in enumerate(os.listdir(test_dspl_path)):\n",
    "        f = os.path.join(test_dspl_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            test_dspl = loadmat(f)\n",
    "            if '__header__' in test_dspl: del test_dspl['__header__']\n",
    "            if '__version__' in test_dspl: del test_dspl['__version__']\n",
    "            if '__globals__' in test_dspl: del test_dspl['__globals__']\n",
    "            test_dspl['name'] = filename\n",
    "            test_dspls = np.append(test_dspls, test_dspl)\n",
    "        else:\n",
    "            continue\n",
    "    test_dspls = np.array(test_dspls)\n",
    "    \n",
    "    # save test traction fields in matrix\n",
    "    test_tracs = [] \n",
    "    for i, filename in enumerate(os.listdir(test_trac_path)):\n",
    "        f = os.path.join(test_trac_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            test_trac = loadmat(f)\n",
    "            if '__header__' in test_trac: del test_trac['__header__']\n",
    "            if '__version__' in test_trac: del test_trac['__version__']\n",
    "            if '__globals__' in test_trac: del test_trac['__globals__']\n",
    "            test_trac['name'] = filename\n",
    "            test_tracs = np.append(test_tracs, test_trac)\n",
    "        else:\n",
    "            continue\n",
    "    test_tracs = np.array(test_tracs)\n",
    "    \n",
    "    return samples, dspl_radials, targets, trac_radials, test_dspls, test_tracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6784bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matFiles_to_npArray(path):\n",
    "\n",
    "    instances = [] \n",
    "    for i, filename in enumerate(os.listdir(path)):\n",
    "        f = os.path.join(path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            instance = loadmat(f)\n",
    "            if '__header__' in instance: del instance['__header__']\n",
    "            if '__version__' in instance: del instance['__version__']\n",
    "            if '__globals__' in instance: del instance['__globals__']\n",
    "            instance['name'] = filename\n",
    "            instances = np.append(instances, instance)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return np.array(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67fe34",
   "metadata": {},
   "source": [
    "Create numpy arrays for samples and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21a7f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = matFiles_to_npArray(dspl_path) \n",
    "dspl_radials = matFiles_to_npArray(dsplRadial_path)\n",
    "targets = matFiles_to_npArray(trac_path)\n",
    "trac_radials = matFiles_to_npArray(tracRadial_path)\n",
    "test_dspls = matFiles_to_npArray(test_dspl_path)\n",
    "test_tracs = matFiles_to_npArray(test_trac_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35841a7b",
   "metadata": {},
   "source": [
    "Split training data into train and validation set using stratified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1b48cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "radial_X_train, radial_X_val, radial_y_train, radial_y_val = train_test_split(dspl_radials, trac_radials, test_size=0.05, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(samples, targets, test_size=0.05)\n",
    "X_train, X_val, y_train, y_val = np.append(radial_X_train, X_train), np.append(radial_X_val, X_val), np.append(radial_y_train, y_train), np.append(radial_y_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12ee31",
   "metadata": {},
   "source": [
    "Drop (meta-) data which is not needed for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90a6180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = np.array([sample['dspl'] for sample in X_train]), np.array([sample['dspl'] for sample in X_val]), np.array([target['trac'] for target in y_train]), np.array([target['trac'] for target in y_val])\n",
    "X_test, y_test = np.array([sample['dspl'] for sample in test_dspls]), np.array([sample['trac'] for sample in test_tracs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82d6e6",
   "metadata": {},
   "source": [
    "### Normalize data  !!! use some kind of max(max(x, y) to preserve the angle !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b50fd8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f15a0d",
   "metadata": {},
   "source": [
    "Extract displacement and traction fields from the data and reshape training set to (samples, channels, depth, heigth, width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "427dc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(array):\n",
    "    \"\"\"current shape is (samples, width, height, depth), reshape to (samples, channels, depth, height, width)\"\"\"\n",
    "    return np.moveaxis(array[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f68b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to (samples, channels, depth, height, width)\n",
    "X_train = np.moveaxis(X_train[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "X_val = np.moveaxis(X_val[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y_train = np.moveaxis(y_train[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y_val = np.moveaxis(y_val[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "X_test = np.moveaxis(X_test[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "y_test = np.moveaxis(y_test[:, np.newaxis], [2, 3, 4], [-1, 3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347a2ed",
   "metadata": {},
   "source": [
    "Convert train and validation data to Pytorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57aa8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).double()\n",
    "X_val = torch.from_numpy(X_val).double()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_val = torch.from_numpy(y_val).double()\n",
    "X_test = torch.from_numpy(X_test).double()\n",
    "y_test = torch.from_numpy(y_test).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac94f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "test_set = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "dataloaders['val'] = DataLoader(val_set, batch_size=2*batch_size, num_workers=8, pin_memory=True)\n",
    "dataloaders['test'] = DataLoader(test_set, batch_size=3*batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410758a",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c1cd2",
   "metadata": {},
   "source": [
    "Sample inital weights for the convolutional layers from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa126d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        torch.nn.init.normal_(module.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77e085",
   "metadata": {},
   "source": [
    "Define custom loss function corresponding to the forward loss function in the Matlab regression layer for image-to-image networks:\n",
    " \n",
    "$${loss} = \\frac{1}{2} \\sum \\limits _{p=1} ^{HWC} (t_{p} - y_{p})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453e6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_Loss, self).__init__();\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        loss = 0.5 * torch.sum(torch.pow(target - predictions, 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd5a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, optimizer, dataloader, train):\n",
    "    loss_fn = Custom_Loss()\n",
    "    \n",
    "    # Set model to training mode\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_rmse = 0.0\n",
    "    \n",
    "    # Iterate over data\n",
    "    for xb, yb in dataloader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # zero the parameters\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        with torch.set_grad_enabled(train):\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            # backward + optimize if in training phase\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2)                \n",
    "                optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(dataloader.dataset)\n",
    "    epoch_rmse = np.sqrt(2 * epoch_loss)\n",
    "    return epoch_loss, epoch_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3874cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, scheduler, dataloaders, max_epochs, patience):\n",
    "    best_val_rmse = np.inf\n",
    "    best_epoch = -1\n",
    "    \n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        train_loss, train_rmse = run_epoch(model, optimizer, dataloaders['train'], train=True)\n",
    "        scheduler.step()\n",
    "        val_loss, val_rmse = run_epoch(model, None, dataloaders['val'], train=False)\n",
    "        print(f\"Epoch {epoch}/{max_epochs}, train_loss: {train_loss:.3f}, train_rmse: {train_rmse:.3f}, val_loss: {val_loss:.3f}, val_rmse: {val_rmse:.3f}\")\n",
    "        \n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_rmse', train_rmse, epoch)\n",
    "        writer.add_scalar('val_loss', val_loss, epoch)\n",
    "        writer.add_scalar('val_rmse', val_rmse, epoch)\n",
    "        \n",
    "        # Save best weights\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_epoch = epoch\n",
    "            best_val_rmse = val_rmse\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        # Early stopping\n",
    "        print(f\"best val_rmse: {best_val_rmse:.3f}, epoch: {epoch}, best_epoch: {best_epoch}, current_patience: {patience - (epoch - best_epoch)}\")\n",
    "        if epoch - best_epoch >= patience:\n",
    "            break\n",
    "        \n",
    "    torch.save(best_model_weights, f'/home/alexrichard/LRZ Sync+Share/ML in Physics/{NAME}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50312c2b",
   "metadata": {},
   "source": [
    "Instantiate the model (including logs for evaluation), the optimizer and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df81a64a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 16:54:19.368943: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-02 16:54:19.368966: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/alexrichard/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:587: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.0000e-04.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0006\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m)\n\u001b[1;32m     13\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7943\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, optimizer, scheduler, dataloaders, max_epochs, patience)\u001b[0m\n\u001b[1;32m      3\u001b[0m best_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     train_loss, train_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      8\u001b[0m     val_loss, val_rmse \u001b[38;5;241m=\u001b[39m run_epoch(model, \u001b[38;5;28;01mNone\u001b[39;00m, dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m], train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, optimizer, dataloader, train)\u001b[0m\n\u001b[1;32m     30\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# statistics\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m epoch_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     36\u001b[0m epoch_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m epoch_loss)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NAME = \"TracNet104-{:%Y-%b-%d %H:%M:%S}\".format(datetime.datetime.now())\n",
    "writer = SummaryWriter(log_dir='logs/{}'.format(NAME))\n",
    "model = TracNet(n_channels=1).double()\n",
    "model.to(device)\n",
    "model.apply(initialize_weight)\n",
    "\n",
    "inputs, targets = next(iter(dataloaders['train']))\n",
    "inputs = inputs.cuda()\n",
    "targets = targets.cuda()\n",
    "writer.add_graph(model, inputs)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0006, weight_decay=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.7943, verbose=True)\n",
    "\n",
    "fit(model, optimizer, scheduler, dataloaders, max_epochs=100, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "974aed5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m(model, Custom_Loss(), dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "loss, rmse = test(model, Custom_Loss(), dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08439f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1266db",
   "metadata": {},
   "source": [
    "Example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ff6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bacabd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410bd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = (pred[0][0]).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.moveaxis(pred_1, [0, 1, 2], [2, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d244cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = savemat('torch_pred_2.mat', {'trac': pred_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_predicted_trac_field = np.array(matlab_prediction['ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_predicted_trac_field.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_predicted_trac_field = np.array(matlab_prediction['ans'])[np.newaxis, :]\n",
    "matlab_predicted_trac_field = np.moveaxis(matlab_predicted_trac_field[:, np.newaxis], [2, 3, 4], [-1, 3, 2])\n",
    "matlab_predicted_trac_field = torch.from_numpy(matlab_predicted_trac_field).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictions, target):\n",
    "    loss = 0.5 * torch.sum(torch.pow(target - predictions, 2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1bea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(predicted_trac_field, gt_trac_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(matlab_predicted_trac_field, gt_trac_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(predicted_trac_field,matlab_predicted_trac_field, atol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363728f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_trac_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53971fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_predicted_trac_field"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
